{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1f7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sentinel-2 압축 파일 해제 시작 ===\n",
      "입력 경로: D:\\Landslide\\data\\sentinel-2\\wildfire_pre_match_2016_2020_buf15_cloud40\n",
      "출력 경로: D:\\Landslide\\data\\sentinel-2\\pre_unzip\n",
      "\n",
      "발견된 ZIP 파일: 128개\n",
      "\n",
      "[1/128] 20151028_R103_T52SDE\n",
      "  - 이미 압축 해제됨\n",
      "[2/128] 20151028_R103_T52SEE\n",
      "  - 이미 압축 해제됨\n",
      "[3/128] 20151217_R103_T52SDD\n",
      "  - 이미 압축 해제됨\n",
      "[4/128] 20170130_R103_T52SDE\n",
      "  - 이미 압축 해제됨\n",
      "[5/128] 20170130_R103_T52SEE\n",
      "  - 이미 압축 해제됨\n",
      "[6/128] 20170202_R003_T52SCE\n",
      "  - 이미 압축 해제됨\n",
      "[7/128] 20170209_R103_T52SDD\n",
      "  - 이미 압축 해제됨\n",
      "[8/128] 20170212_R003_T52SCE\n",
      "  - 이미 압축 해제됨\n",
      "[9/128] 20170304_R003_T52SCD\n",
      "  - 이미 압축 해제됨\n",
      "[10/128] 20170304_R003_T52SCE\n",
      "  - 이미 압축 해제됨\n",
      "[11/128] 20170304_R003_T52SDD\n",
      "  - 이미 압축 해제됨\n",
      "[12/128] 20170304_R003_T52SDE\n",
      "  - 이미 압축 해제됨\n",
      "[13/128] 20170321_R103_T52SDE\n",
      "  - 이미 압축 해제됨\n",
      "[14/128] 20170410_R103_T52SDE\n",
      "  - 이미 압축 해제됨\n",
      "[15/128] 20170413_R003_T52SDE\n",
      "  - 이미 압축 해제됨\n",
      "[16/128] 20170430_R103_T52SCE\n",
      "  - 이미 압축 해제됨\n",
      "[17/128] 20170503_R003_T52SDE\n",
      "  - 이미 압축 해제됨\n",
      "[18/128] 20170609_R103_T52SDE\n",
      "  - 이미 압축 해제됨\n",
      "[19/128] 20170719_R103_T52SEE\n",
      "  - 이미 압축 해제됨\n",
      "[20/128] 20171116_R103_T52SCE\n",
      "  - 이미 압축 해제됨\n",
      "[21/128] 20171116_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[22/128] 20171119_R003_T52SCD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[23/128] 20171229_R003_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[24/128] 20180115_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[25/128] 20180115_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[26/128] 20180207_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[27/128] 20180214_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[28/128] 20180214_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[29/128] 20180214_R103_T52SEE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[30/128] 20180217_R003_T52SCD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[31/128] 20180217_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[32/128] 20180217_R003_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[33/128] 20180326_R103_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[34/128] 20180408_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[35/128] 20180418_R003_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[36/128] 20180624_R103_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[37/128] 20180624_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[38/128] 20181111_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[39/128] 20190113_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[40/128] 20190120_R103_T52SCD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[41/128] 20190120_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[42/128] 20190202_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[43/128] 20190301_R103_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[44/128] 20190301_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[45/128] 20190301_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[46/128] 20190503_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[47/128] 20190510_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[48/128] 20191216_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[49/128] 20200115_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[50/128] 20200214_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[51/128] 20200224_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[52/128] 20200305_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[53/128] 20200305_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[54/128] 20200308_R003_T52SCD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[55/128] 20200308_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[56/128] 20200325_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[57/128] 20200325_R103_T52SEE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[58/128] 20200404_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[59/128] 20201031_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[60/128] 20201110_R103_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[61/128] 20201110_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[62/128] 20201130_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[63/128] 20170727_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[64/128] 20170925_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[65/128] 20170925_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[66/128] 20171022_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[67/128] 20171104_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[68/128] 20171114_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[69/128] 20171121_R103_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[70/128] 20171211_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[71/128] 20171221_R103_T52SCD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[72/128] 20171221_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[73/128] 20171221_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[74/128] 20171231_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[75/128] 20180103_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[76/128] 20180120_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[77/128] 20180123_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[78/128] 20180130_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[79/128] 20180130_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[80/128] 20180301_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[81/128] 20180311_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[82/128] 20180311_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[83/128] 20180324_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[84/128] 20180331_R103_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[85/128] 20180331_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[86/128] 20180420_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[87/128] 20180801_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[88/128] 20180808_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[89/128] 20180818_R103_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[90/128] 20181126_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[91/128] 20181219_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[92/128] 20181226_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[93/128] 20190108_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[94/128] 20190115_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[95/128] 20190128_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[96/128] 20190204_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[97/128] 20190204_R103_T52SEE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[98/128] 20190217_R003_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[99/128] 20190316_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[100/128] 20190316_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[101/128] 20190319_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[102/128] 20190319_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[103/128] 20190326_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[104/128] 20190326_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[105/128] 20190326_R103_T52SEE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[106/128] 20190415_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[107/128] 20191012_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[108/128] 20191101_R103_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[109/128] 20191101_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[110/128] 20191121_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[111/128] 20191121_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[112/128] 20191211_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[113/128] 20200320_R103_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[114/128] 20200320_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[115/128] 20200323_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[116/128] 20200323_R003_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[117/128] 20200409_R103_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[118/128] 20200429_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[119/128] 20200529_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[120/128] 20200529_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[121/128] 20200529_R103_T52SEE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[122/128] 20201006_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[123/128] 20201006_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[124/128] 20201105_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[125/128] 20201125_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[126/128] 20201215_R103_T52SDD\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[127/128] 20201228_R003_T52SCE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "[128/128] 20210104_R103_T52SDE\n",
      "  ▶ 압축 해제 중...\n",
      "  ✓ 완료\n",
      "\n",
      "============================================================\n",
      "=== 압축 해제 완료 ===\n",
      "총 파일: 128개\n",
      "성공: 108개\n",
      "건너뜀: 20개\n",
      "실패: 0개\n",
      "출력 경로: D:\\Landslide\\data\\sentinel-2\\pre_unzip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 경로 설정\n",
    "input_dir = r\"D:\\Landslide\\data\\raw\\sentinel-2\\gyeongnam\\wildfire_pre_match_2016_2020_buf15_cloud40\"\n",
    "output_dir = r\"D:\\Landslide\\data\\raw\\sentinel-2\\gyeongnam\\pre_unzip\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def extract_short_name(filename):\n",
    "    \"\"\"Sentinel-2 파일명에서 고유 식별자 추출\"\"\"\n",
    "    # S2A_MSIL2A_20151028T020802_N0500_R103_T52SDE_20231009T132010.SAFE.zip\n",
    "    # -> 20151028_R103_T52SDE (날짜_궤도_타일)\n",
    "    \n",
    "    # 전체 패턴 매칭\n",
    "    match = re.search(r'(\\d{8})T\\d+_N\\d+_(R\\d+)_(T\\w+)_', filename)\n",
    "    if match:\n",
    "        date = match.group(1)\n",
    "        orbit = match.group(2)\n",
    "        tile = match.group(3)\n",
    "        return f\"{date}_{orbit}_{tile}\"\n",
    "    \n",
    "    # 실패시 원본 파일명 사용 (확장자만 제거)\n",
    "    return filename.replace('.zip', '').replace('.SAFE', '')\n",
    "\n",
    "print(f\"=== Sentinel-2 압축 파일 해제 시작 ===\")\n",
    "print(f\"입력 경로: {input_dir}\")\n",
    "print(f\"출력 경로: {output_dir}\\n\")\n",
    "\n",
    "success_count = 0\n",
    "skip_count = 0\n",
    "fail_count = 0\n",
    "failed_files = []\n",
    "\n",
    "# ZIP 파일 목록 가져오기\n",
    "all_zip_files = []\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            all_zip_files.append((root, file))\n",
    "\n",
    "print(f\"발견된 ZIP 파일: {len(all_zip_files)}개\\n\")\n",
    "\n",
    "for idx, (root, file) in enumerate(all_zip_files, 1):\n",
    "    zip_path = os.path.join(root, file)\n",
    "    \n",
    "    # 짧은 이름 생성\n",
    "    short_name = extract_short_name(file)\n",
    "    output_path = os.path.join(output_dir, short_name)\n",
    "    \n",
    "    print(f\"[{idx}/{len(all_zip_files)}] {short_name}\")\n",
    "    \n",
    "    # GRANULE 폴더 확인\n",
    "    granule_check = os.path.join(output_path, \"GRANULE\")\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        if not os.path.exists(granule_check):\n",
    "            print(f\"  ⚠️  불완전한 압축 해제, 삭제 후 재시도\")\n",
    "            try:\n",
    "                shutil.rmtree(output_path)\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ 폴더 삭제 실패: {e}\")\n",
    "                fail_count += 1\n",
    "                failed_files.append((file, f\"폴더 삭제 실패: {e}\"))\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"  - 이미 압축 해제됨\")\n",
    "            skip_count += 1\n",
    "            continue\n",
    "    \n",
    "    # 압축 해제\n",
    "    try:\n",
    "        print(f\"  ▶ 압축 해제 중...\")\n",
    "        \n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_contents = zip_ref.namelist()\n",
    "            common_prefix = os.path.commonprefix(zip_contents)\n",
    "            if common_prefix and '/' in common_prefix:\n",
    "                common_prefix = common_prefix.split('/')[0]\n",
    "            \n",
    "            temp_dir = output_path + \"_temp\"\n",
    "            if os.path.exists(temp_dir):\n",
    "                shutil.rmtree(temp_dir)\n",
    "            \n",
    "            zip_ref.extractall(temp_dir)\n",
    "            \n",
    "            # 중복 폴더 구조 평탄화\n",
    "            if common_prefix and os.path.isdir(os.path.join(temp_dir, common_prefix)):\n",
    "                nested_path = os.path.join(temp_dir, common_prefix)\n",
    "                shutil.move(nested_path, output_path)\n",
    "                shutil.rmtree(temp_dir)\n",
    "            else:\n",
    "                shutil.move(temp_dir, output_path)\n",
    "        \n",
    "        # GRANULE 폴더 검증\n",
    "        if os.path.exists(granule_check):\n",
    "            print(f\"  ✓ 완료\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"  ✗ GRANULE 폴더 없음\")\n",
    "            fail_count += 1\n",
    "            failed_files.append((file, \"GRANULE 폴더 없음\"))\n",
    "            if os.path.exists(output_path):\n",
    "                shutil.rmtree(output_path)\n",
    "                \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)[:150]\n",
    "        print(f\"  ✗ 오류: {error_msg}\")\n",
    "        fail_count += 1\n",
    "        failed_files.append((file, error_msg))\n",
    "        for cleanup_path in [output_path, output_path + \"_temp\"]:\n",
    "            if os.path.exists(cleanup_path):\n",
    "                try:\n",
    "                    shutil.rmtree(cleanup_path)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"=== 압축 해제 완료 ===\")\n",
    "print(f\"총 파일: {len(all_zip_files)}개\")\n",
    "print(f\"성공: {success_count}개\")\n",
    "print(f\"건너뜀: {skip_count}개\")\n",
    "print(f\"실패: {fail_count}개\")\n",
    "print(f\"출력 경로: {output_dir}\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"=== 실패한 파일 ({len(failed_files)}개) ===\")\n",
    "    for i, (filename, error) in enumerate(failed_files[:10], 1):\n",
    "        print(f\"{i}. {filename[:60]}...\")\n",
    "        print(f\"   오류: {error}\")\n",
    "    \n",
    "    if len(failed_files) > 10:\n",
    "        print(f\"\\n... 외 {len(failed_files) - 10}개 더\")\n",
    "    \n",
    "    # 실패 목록 CSV 저장\n",
    "    fail_csv = os.path.join(output_dir, \"failed_files.csv\")\n",
    "    df_fail = pd.DataFrame(failed_files, columns=['filename', 'error'])\n",
    "    df_fail.to_csv(fail_csv, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n실패 목록 저장: {fail_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec7244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BAIS2 계산 시작 ===\n",
      "입력 경로: D:\\Landslide\\data\\sentinel-2\\pre_unzip\n",
      "출력 경로: D:\\Landslide\\data\\sentinel-2\\outputs\\pre\\BAIS2\n",
      "\n",
      "발견된 SAFE 폴더: 128개\n",
      "\n",
      "[1/128] \n",
      "처리 중: 20151028_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20151028_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -7.326 ~ 2.106\n",
      "     마스킹: 3.4% (SCL:1026123, B4:2885, B12+B8A:4, Invalid:0)\n",
      "[2/128] \n",
      "처리 중: 20151028_R103_T52SEE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20151028_R103_T52SEE_BAIS2.tif\n",
      "     BAIS2: -1.690 ~ 2.115\n",
      "     마스킹: 66.7% (SCL:20099584, B4:16895, B12+B8A:330, Invalid:0)\n",
      "[3/128] \n",
      "처리 중: 20151217_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20151217_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -3.118 ~ 1.985\n",
      "     마스킹: 71.9% (SCL:21671251, B4:49653, B12+B8A:89531, Invalid:0)\n",
      "[4/128] \n",
      "처리 중: 20170130_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170130_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -7.511 ~ 1.779\n",
      "     마스킹: 16.2% (SCL:4856362, B4:19844, B12+B8A:3, Invalid:0)\n",
      "[5/128] \n",
      "처리 중: 20170130_R103_T52SEE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170130_R103_T52SEE_BAIS2.tif\n",
      "     BAIS2: -3.495 ~ 2.030\n",
      "     마스킹: 67.2% (SCL:20247765, B4:0, B12+B8A:1, Invalid:0)\n",
      "[6/128] \n",
      "처리 중: 20170202_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170202_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -4.711 ~ 1.614\n",
      "     마스킹: 25.7% (SCL:7702420, B4:44852, B12+B8A:1782, Invalid:0)\n",
      "[7/128] \n",
      "처리 중: 20170209_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170209_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -0.553 ~ 2.027\n",
      "     마스킹: 80.4% (SCL:24224464, B4:1, B12+B8A:0, Invalid:0)\n",
      "[8/128] \n",
      "처리 중: 20170212_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170212_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -1.292 ~ 1.739\n",
      "     마스킹: 29.6% (SCL:8910057, B4:327, B12+B8A:377, Invalid:0)\n",
      "[9/128] \n",
      "처리 중: 20170304_R003_T52SCD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170304_R003_T52SCD_BAIS2.tif\n",
      "     BAIS2: -2.378 ~ 2.046\n",
      "     마스킹: 42.2% (SCL:12721292, B4:24082, B12+B8A:23450, Invalid:0)\n",
      "[10/128] \n",
      "처리 중: 20170304_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170304_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -2.129 ~ 2.048\n",
      "     마스킹: 1.4% (SCL:407268, B4:2, B12+B8A:1, Invalid:0)\n",
      "[11/128] \n",
      "처리 중: 20170304_R003_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170304_R003_T52SDD_BAIS2.tif\n",
      "     BAIS2: -1.668 ~ 1.368\n",
      "     마스킹: 91.0% (SCL:27413608, B4:23974084, B12+B8A:23956690, Invalid:0)\n",
      "[12/128] \n",
      "처리 중: 20170304_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170304_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -0.753 ~ 1.776\n",
      "     마스킹: 57.4% (SCL:17297383, B4:16578791, B12+B8A:16578791, Invalid:0)\n",
      "[13/128] \n",
      "처리 중: 20170321_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170321_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.759 ~ 1.925\n",
      "     마스킹: 4.3% (SCL:1308000, B4:0, B12+B8A:0, Invalid:0)\n",
      "[14/128] \n",
      "처리 중: 20170410_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170410_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -0.977 ~ 1.566\n",
      "     마스킹: 31.0% (SCL:9351627, B4:29, B12+B8A:0, Invalid:0)\n",
      "[15/128] \n",
      "처리 중: 20170413_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170413_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -4.570 ~ 1.571\n",
      "     마스킹: 56.7% (SCL:17078550, B4:16796269, B12+B8A:16795733, Invalid:0)\n",
      "[16/128] \n",
      "처리 중: 20170430_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170430_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -4.158 ~ 1.232\n",
      "     마스킹: 67.0% (SCL:20201324, B4:20120279, B12+B8A:20118342, Invalid:0)\n",
      "[17/128] \n",
      "처리 중: 20170503_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170503_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -3.193 ~ 1.667\n",
      "     마스킹: 57.0% (SCL:17194172, B4:16978950, B12+B8A:16978950, Invalid:0)\n",
      "[18/128] \n",
      "처리 중: 20170609_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170609_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -3.052 ~ 1.984\n",
      "     마스킹: 20.3% (SCL:6104124, B4:3702, B12+B8A:27, Invalid:0)\n",
      "[19/128] \n",
      "처리 중: 20170719_R103_T52SEE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170719_R103_T52SEE_BAIS2.tif\n",
      "     BAIS2: -2.552 ~ 1.850\n",
      "     마스킹: 77.2% (SCL:23264262, B4:47667, B12+B8A:2, Invalid:0)\n",
      "[20/128] \n",
      "처리 중: 20170727_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170727_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.689 ~ 1.496\n",
      "     마스킹: 57.3% (SCL:17262774, B4:17069210, B12+B8A:17069210, Invalid:0)\n",
      "[21/128] \n",
      "처리 중: 20170925_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170925_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -7.644 ~ 1.800\n",
      "     마스킹: 1.1% (SCL:346096, B4:4063, B12+B8A:0, Invalid:0)\n",
      "[22/128] \n",
      "처리 중: 20170925_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20170925_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.400 ~ 1.793\n",
      "     마스킹: 57.2% (SCL:17235070, B4:16688337, B12+B8A:16688158, Invalid:0)\n",
      "[23/128] \n",
      "처리 중: 20171022_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171022_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.331 ~ 1.756\n",
      "     마스킹: 21.0% (SCL:6338744, B4:0, B12+B8A:0, Invalid:0)\n",
      "[24/128] \n",
      "처리 중: 20171104_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171104_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -8.719 ~ 1.887\n",
      "     마스킹: 2.5% (SCL:706346, B4:72496, B12+B8A:940, Invalid:0)\n",
      "[25/128] \n",
      "처리 중: 20171114_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171114_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.893 ~ 2.007\n",
      "     마스킹: 55.4% (SCL:16694211, B4:16451222, B12+B8A:16451222, Invalid:0)\n",
      "[26/128] \n",
      "처리 중: 20171116_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171116_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -3.159 ~ 1.435\n",
      "     마스킹: 67.9% (SCL:20450864, B4:20394445, B12+B8A:20383557, Invalid:0)\n",
      "[27/128] \n",
      "처리 중: 20171116_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171116_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -4.242 ~ 1.863\n",
      "     마스킹: 1.8% (SCL:531974, B4:5760, B12+B8A:70, Invalid:0)\n",
      "[28/128] \n",
      "처리 중: 20171119_R003_T52SCD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171119_R003_T52SCD_BAIS2.tif\n",
      "     BAIS2: -2.406 ~ 2.071\n",
      "     마스킹: 42.1% (SCL:12690795, B4:32799, B12+B8A:32243, Invalid:0)\n",
      "[29/128] \n",
      "처리 중: 20171121_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171121_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -3.927 ~ 1.441\n",
      "     마스킹: 71.1% (SCL:21402022, B4:20636187, B12+B8A:20615216, Invalid:0)\n",
      "[30/128] \n",
      "처리 중: 20171211_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171211_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -3.529 ~ 1.754\n",
      "     마스킹: 35.5% (SCL:10708549, B4:0, B12+B8A:0, Invalid:0)\n",
      "[31/128] \n",
      "처리 중: 20171221_R103_T52SCD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171221_R103_T52SCD_BAIS2.tif\n",
      "     BAIS2: -8.484 ~ 2.082\n",
      "     마스킹: 77.2% (SCL:23214065, B4:13917263, B12+B8A:14100636, Invalid:0)\n",
      "[32/128] \n",
      "처리 중: 20171221_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171221_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -7.041 ~ 2.067\n",
      "     마스킹: 72.3% (SCL:21710042, B4:301368, B12+B8A:249059, Invalid:0)\n",
      "[33/128] \n",
      "처리 중: 20171221_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171221_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -5.069 ~ 1.956\n",
      "     마스킹: 5.3% (SCL:1423795, B4:167846, B12+B8A:716, Invalid:0)\n",
      "[34/128] \n",
      "처리 중: 20171229_R003_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171229_R003_T52SDD_BAIS2.tif\n",
      "     BAIS2: -6.438 ~ 1.503\n",
      "     마스킹: 90.1% (SCL:27140642, B4:24146132, B12+B8A:24135794, Invalid:0)\n",
      "[35/128] \n",
      "처리 중: 20171231_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20171231_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -0.995 ~ 1.515\n",
      "     마스킹: 4.2% (SCL:1280527, B4:1, B12+B8A:1, Invalid:0)\n",
      "[36/128] \n",
      "처리 중: 20180103_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180103_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -3.251 ~ 1.863\n",
      "     마스킹: 2.6% (SCL:791449, B4:933, B12+B8A:18, Invalid:0)\n",
      "[37/128] \n",
      "처리 중: 20180115_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180115_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -5.495 ~ 2.088\n",
      "     마스킹: 71.6% (SCL:21580356, B4:4281328, B12+B8A:16047, Invalid:0)\n",
      "[38/128] \n",
      "처리 중: 20180115_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180115_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -6.422 ~ 1.810\n",
      "     마스킹: 3.2% (SCL:944243, B4:23463, B12+B8A:26, Invalid:0)\n",
      "[39/128] \n",
      "처리 중: 20180120_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180120_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -0.593 ~ 1.924\n",
      "     마스킹: 71.7% (SCL:21622003, B4:0, B12+B8A:1, Invalid:0)\n",
      "[40/128] \n",
      "처리 중: 20180123_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180123_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -0.873 ~ 1.547\n",
      "     마스킹: 69.8% (SCL:21033999, B4:16847673, B12+B8A:16847673, Invalid:0)\n",
      "[41/128] \n",
      "처리 중: 20180130_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180130_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -1.707 ~ 2.002\n",
      "     마스킹: 84.3% (SCL:25397649, B4:4, B12+B8A:7, Invalid:0)\n",
      "[42/128] \n",
      "처리 중: 20180130_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180130_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -4.001 ~ 1.613\n",
      "     마스킹: 34.4% (SCL:10373867, B4:1909386, B12+B8A:1894395, Invalid:0)\n",
      "[43/128] \n",
      "처리 중: 20180207_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180207_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -0.937 ~ 1.713\n",
      "     마스킹: 11.6% (SCL:3483937, B4:831, B12+B8A:2, Invalid:0)\n",
      "[44/128] \n",
      "처리 중: 20180214_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180214_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -1.694 ~ 2.047\n",
      "     마스킹: 85.7% (SCL:25818837, B4:11242, B12+B8A:4, Invalid:0)\n",
      "[45/128] \n",
      "처리 중: 20180214_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180214_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -0.970 ~ 1.946\n",
      "     마스킹: 12.3% (SCL:3696292, B4:0, B12+B8A:0, Invalid:0)\n",
      "[46/128] \n",
      "처리 중: 20180214_R103_T52SEE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180214_R103_T52SEE_BAIS2.tif\n",
      "     BAIS2: -0.902 ~ 2.054\n",
      "     마스킹: 66.7% (SCL:20098808, B4:0, B12+B8A:0, Invalid:0)\n",
      "[47/128] \n",
      "처리 중: 20180217_R003_T52SCD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180217_R003_T52SCD_BAIS2.tif\n",
      "     BAIS2: -0.808 ~ 2.001\n",
      "     마스킹: 44.0% (SCL:13262151, B4:41620, B12+B8A:41618, Invalid:0)\n",
      "[48/128] \n",
      "처리 중: 20180217_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180217_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -2.583 ~ 1.757\n",
      "     마스킹: 8.4% (SCL:2534848, B4:2, B12+B8A:2, Invalid:0)\n",
      "[49/128] \n",
      "처리 중: 20180217_R003_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180217_R003_T52SDD_BAIS2.tif\n",
      "     BAIS2: -0.548 ~ 1.315\n",
      "     마스킹: 92.0% (SCL:27738145, B4:24196529, B12+B8A:24196525, Invalid:0)\n",
      "[50/128] \n",
      "처리 중: 20180301_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180301_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -5.898 ~ 1.884\n",
      "     마스킹: 12.0% (SCL:3619928, B4:28090, B12+B8A:17, Invalid:0)\n",
      "[51/128] \n",
      "처리 중: 20180311_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180311_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -9.555 ~ 1.777\n",
      "     마스킹: 71.8% (SCL:21620879, B4:3747431, B12+B8A:423, Invalid:0)\n",
      "[52/128] \n",
      "처리 중: 20180311_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180311_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -6.326 ~ 1.390\n",
      "     마스킹: 2.1% (SCL:619489, B4:1160, B12+B8A:2, Invalid:0)\n",
      "[53/128] \n",
      "처리 중: 20180324_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180324_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.054 ~ 1.606\n",
      "     마스킹: 57.1% (SCL:17203545, B4:16678647, B12+B8A:16678370, Invalid:0)\n",
      "[54/128] \n",
      "처리 중: 20180326_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180326_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -0.669 ~ 1.292\n",
      "     마스킹: 69.6% (SCL:20972914, B4:20283327, B12+B8A:20283327, Invalid:0)\n",
      "[55/128] \n",
      "처리 중: 20180331_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180331_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -0.094 ~ 1.425\n",
      "     마스킹: 68.1% (SCL:20533180, B4:20483181, B12+B8A:20483181, Invalid:0)\n",
      "[56/128] \n",
      "처리 중: 20180331_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180331_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.084 ~ 1.687\n",
      "     마스킹: 1.4% (SCL:435431, B4:0, B12+B8A:0, Invalid:0)\n",
      "[57/128] \n",
      "처리 중: 20180408_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180408_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -0.796 ~ 1.379\n",
      "     마스킹: 56.6% (SCL:17071062, B4:16877934, B12+B8A:16877934, Invalid:0)\n",
      "[58/128] \n",
      "처리 중: 20180418_R003_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180418_R003_T52SDD_BAIS2.tif\n",
      "     BAIS2: -0.851 ~ 1.298\n",
      "     마스킹: 90.1% (SCL:27156151, B4:24270836, B12+B8A:24270836, Invalid:0)\n",
      "[59/128] \n",
      "처리 중: 20180420_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180420_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.823 ~ 1.867\n",
      "     마스킹: 1.4% (SCL:407426, B4:0, B12+B8A:1, Invalid:0)\n",
      "[60/128] \n",
      "처리 중: 20180624_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180624_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -0.915 ~ 1.321\n",
      "     마스킹: 69.5% (SCL:20939962, B4:20444964, B12+B8A:20444964, Invalid:0)\n",
      "[61/128] \n",
      "처리 중: 20180624_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180624_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.676 ~ 1.704\n",
      "     마스킹: 14.2% (SCL:4292730, B4:0, B12+B8A:2, Invalid:0)\n",
      "[62/128] \n",
      "처리 중: 20180801_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180801_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.573 ~ 1.564\n",
      "     마스킹: 60.2% (SCL:18137195, B4:16728275, B12+B8A:16728184, Invalid:0)\n",
      "[63/128] \n",
      "처리 중: 20180808_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180808_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -13.700 ~ 1.965\n",
      "     마스킹: 73.7% (SCL:22190174, B4:50491, B12+B8A:1247, Invalid:0)\n",
      "[64/128] \n",
      "처리 중: 20180818_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20180818_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -2.258 ~ 1.191\n",
      "     마스킹: 84.1% (SCL:25349767, B4:22351594, B12+B8A:22351582, Invalid:0)\n",
      "[65/128] \n",
      "처리 중: 20181111_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20181111_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -7.037 ~ 2.163\n",
      "     마스킹: 79.7% (SCL:24022985, B4:6874196, B12+B8A:6641, Invalid:0)\n",
      "[66/128] \n",
      "처리 중: 20181126_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20181126_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -8.085 ~ 2.199\n",
      "     마스킹: 71.7% (SCL:21597343, B4:569045, B12+B8A:472, Invalid:0)\n",
      "[67/128] \n",
      "처리 중: 20181219_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20181219_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.317 ~ 2.016\n",
      "     마스킹: 57.1% (SCL:17201807, B4:16689893, B12+B8A:16689612, Invalid:0)\n",
      "[68/128] \n",
      "처리 중: 20181226_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20181226_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.971 ~ 1.843\n",
      "     마스킹: 13.1% (SCL:3939676, B4:0, B12+B8A:0, Invalid:0)\n",
      "[69/128] \n",
      "처리 중: 20190108_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190108_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -4.560 ~ 1.771\n",
      "     마스킹: 57.0% (SCL:17159522, B4:16806880, B12+B8A:16786519, Invalid:0)\n",
      "[70/128] \n",
      "처리 중: 20190113_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190113_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -1.434 ~ 1.891\n",
      "     마스킹: 2.1% (SCL:641731, B4:276, B12+B8A:1, Invalid:0)\n",
      "[71/128] \n",
      "처리 중: 20190115_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190115_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.777 ~ 1.572\n",
      "     마스킹: 3.5% (SCL:1047050, B4:0, B12+B8A:0, Invalid:0)\n",
      "[72/128] \n",
      "처리 중: 20190120_R103_T52SCD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190120_R103_T52SCD_BAIS2.tif\n",
      "     BAIS2: -6.687 ~ 2.111\n",
      "     마스킹: 76.7% (SCL:23089805, B4:13729788, B12+B8A:13703323, Invalid:0)\n",
      "[73/128] \n",
      "처리 중: 20190120_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190120_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -8.960 ~ 2.071\n",
      "     마스킹: 75.3% (SCL:22669815, B4:781283, B12+B8A:89, Invalid:0)\n",
      "[74/128] \n",
      "처리 중: 20190128_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190128_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -7.740 ~ 1.641\n",
      "     마스킹: 48.6% (SCL:14638604, B4:56405, B12+B8A:2, Invalid:0)\n",
      "[75/128] \n",
      "처리 중: 20190202_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190202_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -4.380 ~ 2.194\n",
      "     마스킹: 58.0% (SCL:17484437, B4:16744770, B12+B8A:16711466, Invalid:0)\n",
      "[76/128] \n",
      "처리 중: 20190204_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190204_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -0.865 ~ 1.394\n",
      "     마스킹: 73.3% (SCL:22100379, B4:0, B12+B8A:0, Invalid:0)\n",
      "[77/128] \n",
      "처리 중: 20190204_R103_T52SEE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190204_R103_T52SEE_BAIS2.tif\n",
      "     BAIS2: -1.077 ~ 2.090\n",
      "     마스킹: 77.8% (SCL:23449449, B4:0, B12+B8A:0, Invalid:0)\n",
      "[78/128] \n",
      "처리 중: 20190217_R003_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190217_R003_T52SDD_BAIS2.tif\n",
      "     BAIS2: -1.642 ~ 1.455\n",
      "     마스킹: 90.1% (SCL:27165047, B4:24101306, B12+B8A:24100776, Invalid:0)\n",
      "[79/128] \n",
      "처리 중: 20190301_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190301_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -1.249 ~ 1.454\n",
      "     마스킹: 69.0% (SCL:20800031, B4:20419078, B12+B8A:20419050, Invalid:0)\n",
      "[80/128] \n",
      "처리 중: 20190301_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190301_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -1.860 ~ 2.070\n",
      "     마스킹: 72.5% (SCL:21853461, B4:1440, B12+B8A:0, Invalid:0)\n",
      "[81/128] \n",
      "처리 중: 20190301_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190301_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.258 ~ 1.860\n",
      "     마스킹: 3.0% (SCL:899052, B4:24, B12+B8A:0, Invalid:0)\n",
      "[82/128] \n",
      "처리 중: 20190316_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190316_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -1.916 ~ 2.073\n",
      "     마스킹: 71.8% (SCL:21651887, B4:2556673, B12+B8A:33, Invalid:0)\n",
      "[83/128] \n",
      "처리 중: 20190316_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190316_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.749 ~ 1.619\n",
      "     마스킹: 14.4% (SCL:4353208, B4:9112, B12+B8A:3, Invalid:0)\n",
      "[84/128] \n",
      "처리 중: 20190319_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190319_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -2.923 ~ 1.830\n",
      "     마스킹: 1.1% (SCL:330297, B4:0, B12+B8A:1, Invalid:0)\n",
      "[85/128] \n",
      "처리 중: 20190319_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190319_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.925 ~ 1.824\n",
      "     마스킹: 55.7% (SCL:16789167, B4:16554814, B12+B8A:16554815, Invalid:0)\n",
      "[86/128] \n",
      "처리 중: 20190326_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190326_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -2.156 ~ 1.941\n",
      "     마스킹: 71.8% (SCL:21652603, B4:7737, B12+B8A:7, Invalid:0)\n",
      "[87/128] \n",
      "처리 중: 20190326_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190326_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.793 ~ 1.895\n",
      "     마스킹: 3.5% (SCL:1051424, B4:710, B12+B8A:0, Invalid:0)\n",
      "[88/128] \n",
      "처리 중: 20190326_R103_T52SEE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190326_R103_T52SEE_BAIS2.tif\n",
      "     BAIS2: -3.323 ~ 2.009\n",
      "     마스킹: 66.5% (SCL:20030118, B4:6, B12+B8A:0, Invalid:0)\n",
      "[89/128] \n",
      "처리 중: 20190415_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190415_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -0.842 ~ 1.893\n",
      "     마스킹: 1.4% (SCL:418569, B4:2, B12+B8A:1, Invalid:0)\n",
      "[90/128] \n",
      "처리 중: 20190503_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190503_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -1.444 ~ 1.556\n",
      "     마스킹: 0.9% (SCL:277891, B4:0, B12+B8A:0, Invalid:0)\n",
      "[91/128] \n",
      "처리 중: 20190510_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20190510_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.632 ~ 1.812\n",
      "     마스킹: 3.2% (SCL:961767, B4:72, B12+B8A:1, Invalid:0)\n",
      "[92/128] \n",
      "처리 중: 20191012_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20191012_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -2.463 ~ 1.836\n",
      "     마스킹: 71.7% (SCL:21624391, B4:192, B12+B8A:2, Invalid:0)\n",
      "[93/128] \n",
      "처리 중: 20191101_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20191101_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -7.020 ~ 1.256\n",
      "     마스킹: 68.1% (SCL:20502703, B4:20453878, B12+B8A:20438671, Invalid:0)\n",
      "[94/128] \n",
      "처리 중: 20191101_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20191101_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -14.873 ~ 1.648\n",
      "     마스킹: 1.8% (SCL:500725, B4:53461, B12+B8A:0, Invalid:0)\n",
      "[95/128] \n",
      "처리 중: 20191121_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20191121_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -6.288 ~ 2.119\n",
      "     마스킹: 71.6% (SCL:21563541, B4:4120775, B12+B8A:169152, Invalid:0)\n",
      "[96/128] \n",
      "처리 중: 20191121_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20191121_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -4.676 ~ 2.009\n",
      "     마스킹: 7.1% (SCL:2106932, B4:27377, B12+B8A:472, Invalid:0)\n",
      "[97/128] \n",
      "처리 중: 20191211_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20191211_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.062 ~ 1.627\n",
      "     마스킹: 49.2% (SCL:14841377, B4:0, B12+B8A:0, Invalid:0)\n",
      "[98/128] \n",
      "처리 중: 20191216_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20191216_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -4.985 ~ 2.063\n",
      "     마스킹: 2.0% (SCL:586285, B4:25325, B12+B8A:411, Invalid:0)\n",
      "[99/128] \n",
      "처리 중: 20200115_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200115_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -8.314 ~ 2.027\n",
      "     마스킹: 4.0% (SCL:1062405, B4:135342, B12+B8A:1281, Invalid:0)\n",
      "[100/128] \n",
      "처리 중: 20200214_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200214_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -10.859 ~ 1.845\n",
      "     마스킹: 6.3% (SCL:1865294, B4:97698, B12+B8A:367, Invalid:0)\n",
      "[101/128] \n",
      "처리 중: 20200224_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200224_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -5.508 ~ 2.152\n",
      "     마스킹: 76.2% (SCL:22954590, B4:2322012, B12+B8A:34, Invalid:0)\n",
      "[102/128] \n",
      "처리 중: 20200305_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200305_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -0.717 ~ 2.000\n",
      "     마스킹: 72.6% (SCL:21875617, B4:5, B12+B8A:239, Invalid:0)\n",
      "[103/128] \n",
      "처리 중: 20200305_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200305_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -5.917 ~ 1.680\n",
      "     마스킹: 6.1% (SCL:1821390, B4:49726, B12+B8A:1635, Invalid:0)\n",
      "[104/128] \n",
      "처리 중: 20200308_R003_T52SCD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200308_R003_T52SCD_BAIS2.tif\n",
      "     BAIS2: -1.246 ~ 2.019\n",
      "     마스킹: 42.1% (SCL:12694593, B4:16993, B12+B8A:17001, Invalid:0)\n",
      "[105/128] \n",
      "처리 중: 20200308_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200308_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -1.110 ~ 1.828\n",
      "     마스킹: 1.8% (SCL:542442, B4:0, B12+B8A:0, Invalid:0)\n",
      "[106/128] \n",
      "처리 중: 20200320_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200320_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -0.744 ~ 1.483\n",
      "     마스킹: 68.5% (SCL:20639009, B4:20567074, B12+B8A:20567072, Invalid:0)\n",
      "[107/128] \n",
      "처리 중: 20200320_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200320_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -2.102 ~ 1.994\n",
      "     마스킹: 72.0% (SCL:21689266, B4:2161, B12+B8A:2, Invalid:0)\n",
      "[108/128] \n",
      "처리 중: 20200323_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200323_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -3.139 ~ 1.828\n",
      "     마스킹: 1.2% (SCL:355132, B4:0, B12+B8A:0, Invalid:0)\n",
      "[109/128] \n",
      "처리 중: 20200323_R003_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200323_R003_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.150 ~ 1.731\n",
      "     마스킹: 56.2% (SCL:16926936, B4:16667504, B12+B8A:16666340, Invalid:0)\n",
      "[110/128] \n",
      "처리 중: 20200325_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200325_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -1.137 ~ 2.033\n",
      "     마스킹: 71.6% (SCL:21582500, B4:39097, B12+B8A:628, Invalid:0)\n",
      "[111/128] \n",
      "처리 중: 20200325_R103_T52SEE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200325_R103_T52SEE_BAIS2.tif\n",
      "     BAIS2: -3.695 ~ 1.949\n",
      "     마스킹: 66.0% (SCL:19895290, B4:0, B12+B8A:0, Invalid:0)\n",
      "[112/128] \n",
      "처리 중: 20200404_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200404_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.756 ~ 1.987\n",
      "     마스킹: 2.6% (SCL:798537, B4:0, B12+B8A:0, Invalid:0)\n",
      "[113/128] \n",
      "처리 중: 20200409_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200409_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -1.485 ~ 1.361\n",
      "     마스킹: 68.3% (SCL:20594317, B4:20529090, B12+B8A:20528600, Invalid:0)\n",
      "[114/128] \n",
      "처리 중: 20200429_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200429_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -3.266 ~ 2.200\n",
      "     마스킹: 1.7% (SCL:497202, B4:951, B12+B8A:195, Invalid:0)\n",
      "[115/128] \n",
      "처리 중: 20200529_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200529_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -1.405 ~ 1.890\n",
      "     마스킹: 76.5% (SCL:23046341, B4:229, B12+B8A:4, Invalid:0)\n",
      "[116/128] \n",
      "처리 중: 20200529_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200529_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -1.877 ~ 1.542\n",
      "     마스킹: 25.3% (SCL:7629513, B4:3290, B12+B8A:154, Invalid:0)\n",
      "[117/128] \n",
      "처리 중: 20200529_R103_T52SEE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20200529_R103_T52SEE_BAIS2.tif\n",
      "     BAIS2: -1.683 ~ 1.780\n",
      "     마스킹: 67.0% (SCL:20181141, B4:2, B12+B8A:0, Invalid:0)\n",
      "[118/128] \n",
      "처리 중: 20201006_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20201006_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -1.433 ~ 2.018\n",
      "     마스킹: 72.6% (SCL:21869279, B4:42, B12+B8A:18, Invalid:0)\n",
      "[119/128] \n",
      "처리 중: 20201006_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20201006_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -2.433 ~ 2.030\n",
      "     마스킹: 4.2% (SCL:1272247, B4:0, B12+B8A:6, Invalid:0)\n",
      "[120/128] \n",
      "처리 중: 20201031_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20201031_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -5.220 ~ 1.997\n",
      "     마스킹: 76.7% (SCL:23100536, B4:1544074, B12+B8A:81, Invalid:0)\n",
      "[121/128] \n",
      "처리 중: 20201105_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20201105_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -4.356 ~ 2.089\n",
      "     마스킹: 3.6% (SCL:1055449, B4:122967, B12+B8A:28, Invalid:0)\n",
      "[122/128] \n",
      "처리 중: 20201110_R103_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20201110_R103_T52SCE_BAIS2.tif\n",
      "     BAIS2: -4.340 ~ 1.556\n",
      "     마스킹: 66.8% (SCL:20131680, B4:20069627, B12+B8A:20053739, Invalid:0)\n",
      "[123/128] \n",
      "처리 중: 20201110_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20201110_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -4.417 ~ 2.076\n",
      "     마스킹: 2.0% (SCL:598295, B4:11034, B12+B8A:1100, Invalid:0)\n",
      "[124/128] \n",
      "처리 중: 20201125_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20201125_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -4.108 ~ 2.067\n",
      "     마스킹: 2.0% (SCL:597555, B4:7710, B12+B8A:294, Invalid:0)\n",
      "[125/128] \n",
      "처리 중: 20201130_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20201130_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -3.416 ~ 1.804\n",
      "     마스킹: 3.8% (SCL:1146868, B4:12873, B12+B8A:128, Invalid:0)\n",
      "[126/128] \n",
      "처리 중: 20201215_R103_T52SDD\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20201215_R103_T52SDD_BAIS2.tif\n",
      "     BAIS2: -7.412 ~ 1.966\n",
      "     마스킹: 75.3% (SCL:22646403, B4:796480, B12+B8A:601329, Invalid:0)\n",
      "[127/128] \n",
      "처리 중: 20201228_R003_T52SCE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20201228_R003_T52SCE_BAIS2.tif\n",
      "     BAIS2: -3.839 ~ 2.123\n",
      "     마스킹: 5.2% (SCL:1581327, B4:1520, B12+B8A:80, Invalid:0)\n",
      "[128/128] \n",
      "처리 중: 20210104_R103_T52SDE\n",
      "  📋 BOA_ADD_OFFSET: -1000\n",
      "  ✅ 20210104_R103_T52SDE_BAIS2.tif\n",
      "     BAIS2: -0.888 ~ 1.682\n",
      "     마스킹: 2.3% (SCL:684715, B4:1, B12+B8A:1, Invalid:0)\n",
      "\n",
      "============================================================\n",
      "=== BAIS2 계산 완료 ===\n",
      "성공: 128개\n",
      "실패: 0개\n",
      "출력 경로: D:\\Landslide\\data\\sentinel-2\\outputs\\pre\\BAIS2\n"
     ]
    }
   ],
   "source": [
    "# BAIS2 계산 셀\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from rasterio.warp import reproject, Resampling\n",
    "\n",
    "# 첫 번째 셀의 output_dir와 일치시킴\n",
    "input_dir = r\"D:\\Landslide\\data\\raw\\sentinel-2\\gyeongnam\\pre_unzip\"\n",
    "output_dir = r\"D:\\Landslide\\data\\processed\\gyeongnam\\S2_outputs\\pre\\BAIS2\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 마스킹할 클래스들 (구름, 해역, 그림자 등)\n",
    "invalid_classes = [0, 1, 3, 6, 8, 9, 10]\n",
    "\n",
    "def extract_boa_offset(safe_folder):\n",
    "    \"\"\"MTD_MSIL2A.xml에서 BOA_ADD_OFFSET 추출\"\"\"\n",
    "    metadata_file = os.path.join(safe_folder, \"MTD_MSIL2A.xml\")\n",
    "    \n",
    "    if not os.path.exists(metadata_file):\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        tree = ET.parse(metadata_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # BOA_ADD_OFFSET 찾기\n",
    "        for elem in root.iter():\n",
    "            if 'BOA_ADD_OFFSET' in elem.tag:\n",
    "                offset_text = elem.text.strip()\n",
    "                if offset_text:\n",
    "                    return int(offset_text)\n",
    "        \n",
    "        return 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "def load_band(granule_path, band_name, resolution='20m'):\n",
    "    \"\"\"특정 밴드 로드 (R20m 폴더 우선)\"\"\"\n",
    "    img_data_path = os.path.join(granule_path, \"IMG_DATA\")\n",
    "    \n",
    "    # R20m 폴더에서 찾기\n",
    "    res_folder = os.path.join(img_data_path, f\"R{resolution}\")\n",
    "    \n",
    "    if os.path.exists(res_folder):\n",
    "        pattern = os.path.join(res_folder, f\"*_{band_name}_{resolution}.jp2\")\n",
    "        files = glob.glob(pattern)\n",
    "        if files:\n",
    "            return files[0]\n",
    "    \n",
    "    # 해상도 표시 없는 파일명 시도\n",
    "    pattern = os.path.join(img_data_path, \"**\", f\"*_{band_name}.jp2\")\n",
    "    files = glob.glob(pattern, recursive=True)\n",
    "    if files:\n",
    "        return files[0]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def calculate_bais2(safe_folder):\n",
    "    \"\"\"단일 SAFE 폴더에 대해 BAIS2 계산\"\"\"\n",
    "    folder_name = os.path.basename(safe_folder)\n",
    "    print(f\"\\n처리 중: {folder_name}\")\n",
    "    \n",
    "    # GRANULE 폴더 찾기\n",
    "    granule_pattern = os.path.join(safe_folder, \"GRANULE\", \"*\")\n",
    "    granule_dirs = glob.glob(granule_pattern)\n",
    "    \n",
    "    if not granule_dirs:\n",
    "        print(f\"  ✗ GRANULE 폴더 없음\")\n",
    "        return False\n",
    "    \n",
    "    granule_path = granule_dirs[0]\n",
    "    \n",
    "    # BOA_ADD_OFFSET 추출\n",
    "    boa_offset = extract_boa_offset(safe_folder)\n",
    "    if boa_offset != 0:\n",
    "        print(f\"  📋 BOA_ADD_OFFSET: {boa_offset}\")\n",
    "    \n",
    "    # 필요한 밴드 파일 경로 찾기\n",
    "    bands_needed = {\n",
    "        'B04': 'B04',\n",
    "        'B06': 'B06', \n",
    "        'B07': 'B07',\n",
    "        'B8A': 'B8A',\n",
    "        'B12': 'B12',\n",
    "        'SCL': 'SCL'\n",
    "    }\n",
    "    \n",
    "    band_files = {}\n",
    "    for key, band_name in bands_needed.items():\n",
    "        file_path = load_band(granule_path, band_name, '20m')\n",
    "        if file_path:\n",
    "            band_files[key] = file_path\n",
    "        else:\n",
    "            print(f\"  ✗ {band_name}: 파일 없음\")\n",
    "            return False\n",
    "    \n",
    "    if len(band_files) != len(bands_needed):\n",
    "        print(f\"  ✗ 필요한 밴드가 모두 없음\")\n",
    "        return False\n",
    "    \n",
    "    # 밴드 데이터 읽기\n",
    "    with rasterio.open(band_files['B04']) as src:\n",
    "        b4 = src.read(1).astype(np.float32)\n",
    "        crs = src.crs\n",
    "        transform = src.transform\n",
    "        width = src.width\n",
    "        height = src.height\n",
    "    \n",
    "    with rasterio.open(band_files['B06']) as src:\n",
    "        b6 = src.read(1).astype(np.float32)\n",
    "    \n",
    "    with rasterio.open(band_files['B07']) as src:\n",
    "        b7 = src.read(1).astype(np.float32)\n",
    "    \n",
    "    with rasterio.open(band_files['B8A']) as src:\n",
    "        b8a = src.read(1).astype(np.float32)\n",
    "    \n",
    "    with rasterio.open(band_files['B12']) as src:\n",
    "        b12 = src.read(1).astype(np.float32)\n",
    "    \n",
    "    with rasterio.open(band_files['SCL']) as src:\n",
    "        scl = src.read(1)\n",
    "    \n",
    "    # BOA offset 적용 및 정규화 (DN -> 반사도)\n",
    "    quantification_value = 10000\n",
    "    b4 = (b4 + boa_offset) / quantification_value\n",
    "    b6 = (b6 + boa_offset) / quantification_value\n",
    "    b7 = (b7 + boa_offset) / quantification_value\n",
    "    b8a = (b8a + boa_offset) / quantification_value\n",
    "    b12 = (b12 + boa_offset) / quantification_value\n",
    "    \n",
    "    # 음수 값을 0으로 클리핑 (물리적으로 불가능한 반사도 제거)\n",
    "    b4 = np.clip(b4, 0, None)\n",
    "    b6 = np.clip(b6, 0, None)\n",
    "    b7 = np.clip(b7, 0, None)\n",
    "    b8a = np.clip(b8a, 0, None)\n",
    "    b12 = np.clip(b12, 0, None)\n",
    "    \n",
    "    # 0으로 나누기 방지를 위한 epsilon\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    # === 개선된 마스킹 로직 ===\n",
    "    # 1. SCL 기반 마스크 (구름, 그림자, 물 등)\n",
    "    scl_mask = np.isin(scl, invalid_classes)\n",
    "    \n",
    "    # 2. Red 밴드(b4)가 매우 작은 픽셀 마스크 (division by near-zero 방지)\n",
    "    b4_invalid_mask = b4 < epsilon\n",
    "    \n",
    "    # 3. 분모가 0에 가까운 경우 마스크\n",
    "    b12_b8a_sum = b12 + b8a\n",
    "    b12_b8a_invalid_mask = b12_b8a_sum < epsilon\n",
    "    \n",
    "    # BAIS2 계산 (마스킹 전)\n",
    "    # 분모를 epsilon으로 대체하여 계산\n",
    "    b4_safe = np.where(b4 < epsilon, epsilon, b4)\n",
    "    b12_b8a_sum_safe = np.where(b12_b8a_sum < epsilon, epsilon, b12_b8a_sum)\n",
    "    \n",
    "    term1 = 1 - np.sqrt((b6 * b7 * b8a) / b4_safe)\n",
    "    term2 = (b12 - b8a) / np.sqrt(b12_b8a_sum_safe) + 1\n",
    "    bais2 = term1 * term2\n",
    "    \n",
    "    # 4. inf 또는 nan 값 마스크\n",
    "    invalid_values_mask = ~np.isfinite(bais2)\n",
    "    \n",
    "    # 5. 최종 마스크 통합\n",
    "    final_mask = scl_mask | b4_invalid_mask | b12_b8a_invalid_mask | invalid_values_mask\n",
    "    \n",
    "    # 최종 마스킹 적용\n",
    "    bais2[final_mask] = np.nan\n",
    "    \n",
    "    # 마스킹 통계\n",
    "    total_pixels = final_mask.size\n",
    "    scl_masked = np.sum(scl_mask)\n",
    "    b4_masked = np.sum(b4_invalid_mask)\n",
    "    b12_b8a_masked = np.sum(b12_b8a_invalid_mask)\n",
    "    invalid_masked = np.sum(invalid_values_mask)\n",
    "    total_masked = np.sum(final_mask)\n",
    "    masked_ratio = (total_masked / total_pixels) * 100\n",
    "    \n",
    "    # GeoTIFF로 저장 (GTiff 드라이버 명시)\n",
    "    output_filename = f\"{folder_name}_BAIS2.tif\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    # GeoTIFF 프로파일 설정\n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'dtype': rasterio.float32,\n",
    "        'count': 1,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'crs': crs,\n",
    "        'transform': transform,\n",
    "        'compress': 'lzw',\n",
    "        'nodata': np.nan\n",
    "    }\n",
    "    \n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(bais2, 1)\n",
    "        dst.set_band_description(1, 'BAIS2')\n",
    "        dst.update_tags(1, \n",
    "                       BAND_NAME='BAIS2',\n",
    "                       DESCRIPTION='Burned Area Index for Sentinel-2',\n",
    "                       FORMULA='(1 - sqrt((B6*B7*B8A)/B4)) * ((B12-B8A)/sqrt(B12+B8A) + 1)',\n",
    "                       BOA_OFFSET=str(boa_offset),\n",
    "                       TOTAL_MASKED_RATIO=f'{masked_ratio:.1f}%',\n",
    "                       SCL_MASKED_PIXELS=str(scl_masked),\n",
    "                       B4_INVALID_PIXELS=str(b4_masked),\n",
    "                       B12_B8A_INVALID_PIXELS=str(b12_b8a_masked),\n",
    "                       INVALID_VALUES_PIXELS=str(invalid_masked))\n",
    "    \n",
    "    print(f\"  ✅ {output_filename}\")\n",
    "    print(f\"     BAIS2: {np.nanmin(bais2):.3f} ~ {np.nanmax(bais2):.3f}\")\n",
    "    print(f\"     마스킹: {masked_ratio:.1f}% (SCL:{scl_masked}, B4:{b4_masked}, B12+B8A:{b12_b8a_masked}, Invalid:{invalid_masked})\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# 메인 실행\n",
    "print(f\"=== BAIS2 계산 시작 ===\")\n",
    "print(f\"입력 경로: {input_dir}\")\n",
    "print(f\"출력 경로: {output_dir}\\n\")\n",
    "\n",
    "# 모든 SAFE 폴더 찾기\n",
    "safe_folders = [d for d in glob.glob(os.path.join(input_dir, \"*\")) if os.path.isdir(d)]\n",
    "print(f\"발견된 SAFE 폴더: {len(safe_folders)}개\\n\")\n",
    "\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "failed_list = []\n",
    "\n",
    "for idx, safe_folder in enumerate(safe_folders, 1):\n",
    "    try:\n",
    "        print(f\"[{idx}/{len(safe_folders)}]\", end=\" \")\n",
    "        if calculate_bais2(safe_folder):\n",
    "            success_count += 1\n",
    "        else:\n",
    "            fail_count += 1\n",
    "            failed_list.append(os.path.basename(safe_folder))\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ 오류: {str(e)[:100]}\")\n",
    "        fail_count += 1\n",
    "        failed_list.append(os.path.basename(safe_folder))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"=== BAIS2 계산 완료 ===\")\n",
    "print(f\"성공: {success_count}개\")\n",
    "print(f\"실패: {fail_count}개\")\n",
    "print(f\"출력 경로: {output_dir}\")\n",
    "\n",
    "if failed_list:\n",
    "    print(f\"\\n실패 목록 ({len(failed_list)}개):\")\n",
    "    for i, name in enumerate(failed_list[:10], 1):\n",
    "        print(f\"  {i}. {name}\")\n",
    "    if len(failed_list) > 10:\n",
    "        print(f\"  ... 외 {len(failed_list) - 10}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6a7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "=== BAIS2 히스토그램 분포 분석 시작 ===\n",
      "======================================================================\n",
      "입력 경로: D:\\Landslide\\data\\sentinel-2\\outputs\\pre\\BAIS2\n",
      "분석 결과 저장: D:\\Landslide\\data\\sentinel-2\\outputs\\pre\\BAIS2_analysis\n",
      "\n",
      "[1/5] 데이터 수집 및 기본 통계 계산 중...\n",
      "      발견된 BAIS2 파일: 128개\n",
      "\n",
      "      메모리 효율을 위해 각 영상당 2,000개 픽셀만 샘플링합니다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      통계 수집:   3%|▎         | 4/128 [00:09<05:04,  2.45s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(tif_path)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(tif_path) \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[1;32m---> 51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# 유효한 픽셀만 추출 (NaN 제외)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     valid_data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(data)]\n",
      "File \u001b[1;32mrasterio\\\\_io.pyx:644\u001b[0m, in \u001b[0;36mrasterio._io.DatasetReaderBase.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\\\_io.pyx:969\u001b[0m, in \u001b[0;36mrasterio._io.DatasetReaderBase._read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\\\_io.pyx:199\u001b[0m, in \u001b[0;36mrasterio._io.io_multi_band\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\qgispy_new\\lib\\contextlib.py:139\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, typ, value, traceback):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 위의 셀에서 생성된 BAIS2의 tif파일들의 영상 각각에 대해 히스토그램(빈도)를 계산하고, 150개 히스토그램을 종합하여, 각 영상의 히스토그램이 서로 얼마나 다른 분포를 가지는지, 분석하는 셀\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 한글 폰트 설정 (Windows 환경)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "input_dir = r\"D:\\Landslide\\data\\processed\\gyeongnam\\S2_outputs\\pre\\BAIS2\"\n",
    "analysis_output_dir = os.path.join(os.path.dirname(input_dir), \"BAIS2_analysis\")\n",
    "\n",
    "if not os.path.exists(analysis_output_dir):\n",
    "    os.makedirs(analysis_output_dir)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"=== BAIS2 히스토그램 분포 분석 시작 ===\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"입력 경로: {input_dir}\")\n",
    "print(f\"분석 결과 저장: {analysis_output_dir}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 1단계: 데이터 수집 및 전처리 (메모리 효율적)\n",
    "# ============================================================\n",
    "print(\"[1/5] 데이터 수집 및 기본 통계 계산 중...\")\n",
    "\n",
    "tif_files = sorted(glob.glob(os.path.join(input_dir, \"*.tif\")))\n",
    "print(f\"      발견된 BAIS2 파일: {len(tif_files)}개\\n\")\n",
    "\n",
    "if len(tif_files) == 0:\n",
    "    print(\"❌ 분석할 TIF 파일이 없습니다.\")\n",
    "    raise FileNotFoundError(\"No TIF files found\")\n",
    "\n",
    "# 기본 통계 수집 (메모리 효율적)\n",
    "statistics_list = []\n",
    "sample_per_image = 2000  # 각 영상당 샘플링할 픽셀 수 (더 작게)\n",
    "\n",
    "print(f\"      메모리 효율을 위해 각 영상당 {sample_per_image:,}개 픽셀만 샘플링합니다.\\n\")\n",
    "\n",
    "for tif_path in tqdm(tif_files, desc=\"      통계 수집\"):\n",
    "    filename = os.path.basename(tif_path)\n",
    "    \n",
    "    with rasterio.open(tif_path) as src:\n",
    "        data = src.read(1)\n",
    "        \n",
    "        # 유효한 픽셀만 추출 (NaN 제외)\n",
    "        valid_data = data[~np.isnan(data)]\n",
    "        \n",
    "        if len(valid_data) > 0:\n",
    "            stats = {\n",
    "                'filename': filename,\n",
    "                'min': float(np.min(valid_data)),\n",
    "                'max': float(np.max(valid_data)),\n",
    "                'mean': float(np.mean(valid_data)),\n",
    "                'median': float(np.median(valid_data)),\n",
    "                'std': float(np.std(valid_data)),\n",
    "                'valid_pixels': len(valid_data),\n",
    "                'total_pixels': data.size,\n",
    "                'valid_ratio': len(valid_data) / data.size\n",
    "            }\n",
    "            statistics_list.append(stats)\n",
    "\n",
    "df_stats = pd.DataFrame(statistics_list)\n",
    "total_valid_pixels = df_stats['valid_pixels'].sum()\n",
    "\n",
    "print(f\"\\n✅ 통계 수집 완료: {len(df_stats)}개 영상\")\n",
    "print(f\"   전체 유효 픽셀 수: {total_valid_pixels:,}개\")\n",
    "print(f\"   BAIS2 전체 범위: [{df_stats['min'].min():.3f}, {df_stats['max'].max():.3f}]\")\n",
    "print(f\"   평균의 평균: {df_stats['mean'].mean():.3f} ± {df_stats['mean'].std():.3f}\")\n",
    "print(f\"   표준편차의 평균: {df_stats['std'].mean():.3f}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 2단계: 히스토그램 계산\n",
    "# ============================================================\n",
    "print(\"[2/5] 히스토그램 계산 중...\")\n",
    "\n",
    "# 공통 bin 범위 설정 (전체 데이터 기준)\n",
    "global_min = df_stats['min'].min()\n",
    "global_max = df_stats['max'].max()\n",
    "n_bins = 50  # bins 수를 줄여서 메모리 절약\n",
    "bins = np.linspace(global_min, global_max, n_bins + 1)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "print(f\"      Bins: {n_bins}개 (범위: [{global_min:.3f}, {global_max:.3f}])\")\n",
    "\n",
    "# 각 영상별 히스토그램 계산\n",
    "histograms = []  # 정규화된 히스토그램 저장\n",
    "histogram_counts = []  # 원본 카운트 저장\n",
    "\n",
    "for tif_path in tqdm(tif_files, desc=\"      히스토그램 계산\"):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        data = src.read(1)\n",
    "        valid_data = data[~np.isnan(data)]\n",
    "        \n",
    "        if len(valid_data) > 0:\n",
    "            # 히스토그램 계산\n",
    "            counts, _ = np.histogram(valid_data, bins=bins)\n",
    "            histogram_counts.append(counts)\n",
    "            \n",
    "            # 정규화 (확률 분포로 변환)\n",
    "            normalized = counts / counts.sum()\n",
    "            histograms.append(normalized)\n",
    "\n",
    "histograms = np.array(histograms)\n",
    "histogram_counts = np.array(histogram_counts)\n",
    "\n",
    "print(f\"\\n✅ 히스토그램 계산 완료: {histograms.shape[0]}개 영상\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 3단계: 분포 차이 분석\n",
    "# ============================================================\n",
    "print(\"[3/5] 분포 차이 분석 중...\")\n",
    "\n",
    "# 3-1. 통계적 변동성\n",
    "mean_cv = df_stats['mean'].std() / df_stats['mean'].mean()  # 변동 계수\n",
    "std_cv = df_stats['std'].std() / df_stats['std'].mean()\n",
    "\n",
    "print(f\"      평균의 변동 계수 (CV): {mean_cv:.4f}\")\n",
    "print(f\"      표준편차의 변동 계수 (CV): {std_cv:.4f}\")\n",
    "\n",
    "# 3-2. 평균 히스토그램 계산\n",
    "mean_histogram = histograms.mean(axis=0)\n",
    "std_histogram = histograms.std(axis=0)\n",
    "\n",
    "# 3-3. Jensen-Shannon Divergence 계산 (샘플링: 계산량 감소)\n",
    "print(f\"\\n      분포 거리 계산 중 (샘플링)...\")\n",
    "n_samples = min(len(histograms), 30)  # 샘플 수를 더 줄임\n",
    "sample_indices = np.random.choice(len(histograms), n_samples, replace=False)\n",
    "\n",
    "js_divergences = []\n",
    "\n",
    "for i in tqdm(range(n_samples), desc=\"      JS Divergence\"):\n",
    "    idx = sample_indices[i]\n",
    "    # 평균 분포와의 거리\n",
    "    js_dist = jensenshannon(histograms[idx], mean_histogram)\n",
    "    js_divergences.append(js_dist)\n",
    "\n",
    "print(f\"\\n✅ 분포 차이 분석 완료\")\n",
    "print(f\"   평균 JS Divergence: {np.mean(js_divergences):.4f} ± {np.std(js_divergences):.4f}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 4단계: 시각화\n",
    "# ============================================================\n",
    "print(\"[4/5] 시각화 생성 중...\")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))  # 크기를 줄임\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 4-1. 전체 통합 히스토그램 (개별 히스토그램 합산)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "# 모든 영상의 히스토그램을 합산하여 전체 분포 표현\n",
    "total_histogram = histogram_counts.sum(axis=0)\n",
    "ax1.bar(bin_centers, total_histogram, width=(bins[1]-bins[0])*0.9, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax1.set_xlabel('BAIS2 값', fontsize=12)\n",
    "ax1.set_ylabel('빈도 (픽셀 수)', fontsize=12)\n",
    "ax1.set_title(f'전체 BAIS2 분포 통합 히스토그램 ({len(tif_files)}개 영상, {total_valid_pixels:,}개 픽셀)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.axvline(df_stats['mean'].mean(), color='red', linestyle='--', linewidth=2, label=f'전체 평균: {df_stats[\"mean\"].mean():.3f}')\n",
    "ax1.legend(fontsize=11)\n",
    "\n",
    "# 4-2. 개별 히스토그램 오버레이 (샘플)\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "n_overlay = min(20, len(histograms))  # 샘플 수 줄임\n",
    "overlay_indices = np.random.choice(len(histograms), n_overlay, replace=False)\n",
    "for idx in overlay_indices:\n",
    "    ax2.plot(bin_centers, histograms[idx], alpha=0.3, linewidth=0.8)\n",
    "ax2.plot(bin_centers, mean_histogram, color='red', linewidth=2.5, label='평균 분포')\n",
    "ax2.fill_between(bin_centers, mean_histogram - std_histogram, mean_histogram + std_histogram, \n",
    "                  color='red', alpha=0.2, label='±1 표준편차')\n",
    "ax2.set_xlabel('BAIS2 값', fontsize=10)\n",
    "ax2.set_ylabel('정규화된 빈도', fontsize=10)\n",
    "ax2.set_title(f'개별 히스토그램 오버레이 ({n_overlay}개 샘플)', fontsize=12, fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# 4-3. 통계 박스플롯 (평균)\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "bp1 = ax3.boxplot([df_stats['mean']], positions=[1], widths=0.6, patch_artist=True,\n",
    "                    boxprops=dict(facecolor='lightcoral', alpha=0.7),\n",
    "                    medianprops=dict(color='darkred', linewidth=2))\n",
    "ax3.set_ylabel('BAIS2 평균', fontsize=10)\n",
    "ax3.set_title('영상별 평균 분포', fontsize=12, fontweight='bold')\n",
    "ax3.set_xticks([1])\n",
    "ax3.set_xticklabels([f'{len(df_stats)}개 영상'])\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "ax3.text(1.3, df_stats['mean'].median(), f\"중앙값: {df_stats['mean'].median():.3f}\\nCV: {mean_cv:.3f}\", \n",
    "         fontsize=9, verticalalignment='center')\n",
    "\n",
    "# 4-4. JS Divergence 분포\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "ax4.hist(js_divergences, bins=20, color='orange', alpha=0.7, edgecolor='black')\n",
    "ax4.set_xlabel('Jensen-Shannon Divergence', fontsize=10)\n",
    "ax4.set_ylabel('빈도', fontsize=10)\n",
    "ax4.set_title(f'평균 분포와의 JS Divergence ({len(js_divergences)}개 샘플)', fontsize=12, fontweight='bold')\n",
    "ax4.axvline(np.mean(js_divergences), color='red', linestyle='--', linewidth=2, \n",
    "            label=f'평균: {np.mean(js_divergences):.4f}')\n",
    "ax4.legend(fontsize=9)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('BAIS2 히스토그램 분포 종합 분석', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# 저장\n",
    "fig_path = os.path.join(analysis_output_dir, \"histogram_analysis.png\")\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"      ✅ 시각화 저장: {fig_path}\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 5단계: 결과 저장\n",
    "# ============================================================\n",
    "print(\"\\n[5/5] 분석 결과 저장 중...\")\n",
    "\n",
    "# 5-1. 통계 요약 CSV\n",
    "stats_csv = os.path.join(analysis_output_dir, \"statistics_summary.csv\")\n",
    "df_stats.to_csv(stats_csv, index=False, encoding='utf-8-sig')\n",
    "print(f\"      ✅ {stats_csv}\")\n",
    "\n",
    "# 5-2. 히스토그램 데이터 CSV\n",
    "df_histogram = pd.DataFrame(\n",
    "    histogram_counts,\n",
    "    index=[os.path.basename(f) for f in tif_files],\n",
    "    columns=[f'bin_{i}' for i in range(n_bins)]\n",
    ")\n",
    "histogram_csv = os.path.join(analysis_output_dir, \"histogram_data.csv\")\n",
    "df_histogram.to_csv(histogram_csv, encoding='utf-8-sig')\n",
    "print(f\"      ✅ {histogram_csv}\")\n",
    "\n",
    "# 5-3. 분포 거리 CSV\n",
    "df_distances = pd.DataFrame({\n",
    "    'sample_index': sample_indices[:len(js_divergences)],\n",
    "    'filename': [os.path.basename(tif_files[i]) for i in sample_indices[:len(js_divergences)]],\n",
    "    'js_divergence': js_divergences\n",
    "})\n",
    "distances_csv = os.path.join(analysis_output_dir, \"distribution_distances.csv\")\n",
    "df_distances.to_csv(distances_csv, index=False, encoding='utf-8-sig')\n",
    "print(f\"      ✅ {distances_csv}\")\n",
    "\n",
    "# 5-4. 종합 분석 리포트 TXT\n",
    "report_path = os.path.join(analysis_output_dir, \"analysis_report.txt\")\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"BAIS2 히스토그램 분포 분석 리포트\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(f\"분석 일시: {pd.Timestamp.now()}\\n\")\n",
    "    f.write(f\"입력 경로: {input_dir}\\n\")\n",
    "    f.write(f\"총 영상 수: {len(df_stats)}개\\n\")\n",
    "    f.write(f\"총 유효 픽셀: {total_valid_pixels:,}개\\n\\n\")\n",
    "    \n",
    "    f.write(\"[1] BAIS2 값 범위\\n\")\n",
    "    f.write(f\"  - 최소값: {df_stats['min'].min():.6f}\\n\")\n",
    "    f.write(f\"  - 최대값: {df_stats['max'].max():.6f}\\n\")\n",
    "    f.write(f\"  - 범위: {df_stats['max'].max() - df_stats['min'].min():.6f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"[2] 영상별 평균 통계\\n\")\n",
    "    f.write(f\"  - 평균의 평균: {df_stats['mean'].mean():.6f}\\n\")\n",
    "    f.write(f\"  - 평균의 표준편차: {df_stats['mean'].std():.6f}\\n\")\n",
    "    f.write(f\"  - 평균의 변동계수(CV): {mean_cv:.6f}\\n\")\n",
    "    f.write(f\"  - 평균의 범위: [{df_stats['mean'].min():.6f}, {df_stats['mean'].max():.6f}]\\n\\n\")\n",
    "    \n",
    "    f.write(\"[3] 영상별 표준편차 통계\\n\")\n",
    "    f.write(f\"  - 표준편차의 평균: {df_stats['std'].mean():.6f}\\n\")\n",
    "    f.write(f\"  - 표준편차의 표준편차: {df_stats['std'].std():.6f}\\n\")\n",
    "    f.write(f\"  - 표준편차의 변동계수(CV): {std_cv:.6f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"[4] 분포 차이 분석\\n\")\n",
    "    f.write(f\"  - 평균 JS Divergence: {np.mean(js_divergences):.6f} ± {np.std(js_divergences):.6f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"[5] 해석\\n\")\n",
    "    if mean_cv < 0.1:\n",
    "        interpretation = \"매우 균일한 분포 - 영상 간 BAIS2 분포가 매우 유사함\"\n",
    "    elif mean_cv < 0.3:\n",
    "        interpretation = \"보통 변동성 - 영상 간 BAIS2 분포에 적절한 차이가 존재함\"\n",
    "    else:\n",
    "        interpretation = \"높은 변동성 - 영상 간 BAIS2 분포가 크게 상이함. 정규화 고려 필요\"\n",
    "    f.write(f\"  {interpretation}\\n\\n\")\n",
    "    \n",
    "    f.write(\"[6] 권장사항\\n\")\n",
    "    if mean_cv >= 0.3:\n",
    "        f.write(\"  - Z-score 정규화 또는 Min-Max 정규화 적용 검토\\n\")\n",
    "        f.write(\"  - 이상치(outlier) 영상 제거 검토\\n\")\n",
    "    else:\n",
    "        f.write(\"  - 현재 분포는 분석에 적합한 수준\\n\")\n",
    "    f.write(\"  - 시계열 분석 시 계절별/연도별 분포 차이 추가 분석 권장\\n\")\n",
    "\n",
    "print(f\"      ✅ {report_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"=== 분석 완료 ===\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n 결과 저장 위치: {analysis_output_dir}\")\n",
    "print(f\"\\n 핵심 결과:\")\n",
    "print(f\"   • 평균의 변동계수(CV): {mean_cv:.4f}\")\n",
    "if mean_cv < 0.1:\n",
    "    print(f\"   → 매우 균일한 분포 (정규화 불필요)\")\n",
    "elif mean_cv < 0.3:\n",
    "    print(f\"   → 보통 수준의 변동성 (정규화 선택적)\")\n",
    "else:\n",
    "    print(f\"   → 높은 변동성 (정규화 권장)\")\n",
    "\n",
    "print(f\"\\n   • 평균 JS Divergence: {np.mean(js_divergences):.4f}\")\n",
    "print(f\"\\n 분석 리포트를 확인하세요: {report_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e5331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "=== BAIS2 산지지역 마스킹 시작 ===\n",
      "======================================================================\n",
      "입력 경로: D:\\Landslide\\data\\sentinel-2\\outputs\\pre\\BAIS2\n",
      "출력 경로: D:\\Landslide\\data\\sentinel-2\\outputs\\pre\\BAIS2_masked\n",
      "마스크 파일: D:\\Landslide\\data\\gyeongnam\\terrain_information\\gyeongnam_forest_mask.gpkg\n",
      "\n",
      "[1/3] 산지지역 마스크 로드 중...\n",
      "   ✅ 마스크 로드 완료\n",
      "      피처 수: 1개\n",
      "      CRS: EPSG:5179\n",
      "      총 면적: 6897.18 km²\n",
      "\n",
      "[2/3] BAIS2 래스터 파일 마스킹 중...\n",
      "   발견된 TIF 파일: 128개\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   처리 중: 100%|██████████| 128/128 [1:10:47<00:00, 33.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ✅ 마스킹 완료: 128개 성공, 0개 실패\n",
      "\n",
      "[3/3] 결과 요약 및 저장 중...\n",
      "\n",
      "   [마스킹 통계]\n",
      "   - 평균 유효 픽셀 비율: 32.54%\n",
      "   - 총 유효 픽셀: 676,996,838개\n",
      "   - 총 마스킹된 픽셀: 1,511,470,267개\n",
      "\n",
      "   ✅ 마스킹 결과 저장: D:\\Landslide\\data\\sentinel-2\\outputs\\pre\\BAIS2_masked\\masking_results.csv\n",
      "   ✅ 리포트 저장: D:\\Landslide\\data\\sentinel-2\\outputs\\pre\\BAIS2_masked\\masking_report.txt\n",
      "\n",
      "======================================================================\n",
      "=== 마스킹 완료 ===\n",
      "======================================================================\n",
      "\n",
      " 총 128개 파일이 마스킹되어 저장되었습니다.\n",
      " 출력 경로: D:\\Landslide\\data\\sentinel-2\\outputs\\pre\\BAIS2_masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BAIS2 래스터 산지지역 마스킹\n",
    "# ============================================================\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================================================\n",
    "# 1. 기본 설정 및 경로 정의\n",
    "# ============================================================\n",
    "# 원본 BAIS2 래스터 파일 경로\n",
    "input_dir = r\"D:\\Landslide\\data\\processed\\gyeongnam\\S2_outputs\\pre\\BAIS2\"\n",
    "\n",
    "# 마스킹된 결과를 저장할 경로\n",
    "output_dir = r\"D:\\Landslide\\data\\processed\\gyeongnam\\S2_outputs\\pre\\BAIS2_masked\"\n",
    "\n",
    "# 산지지역 마스크 파일 경로\n",
    "mask_path = r\"D:\\Landslide\\data\\processed\\gyeongnam\\terrain_information\\gyeongnam_forest_mask.gpkg\"\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"=== BAIS2 산지지역 마스킹 시작 ===\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"입력 경로: {input_dir}\")\n",
    "print(f\"출력 경로: {output_dir}\")\n",
    "print(f\"마스크 파일: {mask_path}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. 산지지역 마스크 로드\n",
    "# ============================================================\n",
    "print(\"[1/3] 산지지역 마스크 로드 중...\")\n",
    "\n",
    "if not os.path.exists(mask_path):\n",
    "    raise FileNotFoundError(f\"마스크 파일을 찾을 수 없습니다: {mask_path}\")\n",
    "\n",
    "# GeoPackage 읽기\n",
    "gdf_mask = gpd.read_file(mask_path)\n",
    "\n",
    "print(f\"   ✅ 마스크 로드 완료\")\n",
    "print(f\"      피처 수: {len(gdf_mask)}개\")\n",
    "print(f\"      CRS: {gdf_mask.crs}\")\n",
    "print(f\"      총 면적: {gdf_mask.geometry.area.sum() / 1e6:.2f} km²\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. 모든 BAIS2 래스터 파일 마스킹\n",
    "# ============================================================\n",
    "print(\"[2/3] BAIS2 래스터 파일 마스킹 중...\")\n",
    "\n",
    "# 모든 TIF 파일 목록 가져오기\n",
    "all_tif_files = sorted(glob.glob(os.path.join(input_dir, \"*.tif\")))\n",
    "print(f\"   발견된 TIF 파일: {len(all_tif_files)}개\\n\")\n",
    "\n",
    "# 마스킹 결과 저장\n",
    "masking_results = []\n",
    "success_count = 0\n",
    "failed_count = 0\n",
    "failed_files = []\n",
    "\n",
    "for idx, tif_path in enumerate(tqdm(all_tif_files, desc=\"   처리 중\"), 1):\n",
    "    filename = os.path.basename(tif_path)\n",
    "    \n",
    "    try:\n",
    "        # 래스터 파일 열기\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            src_crs = src.crs\n",
    "            \n",
    "            # 마스크를 래스터와 동일한 CRS로 변환 (필요시)\n",
    "            if gdf_mask.crs != src_crs:\n",
    "                gdf_mask_reprojected = gdf_mask.to_crs(src_crs)\n",
    "            else:\n",
    "                gdf_mask_reprojected = gdf_mask\n",
    "            \n",
    "            # 마스크 적용하여 래스터 자르기\n",
    "            # crop=True: 마스크 영역에 맞게 래스터 크기 조정\n",
    "            # all_touched=False: 폴리곤 내부에 중심이 있는 픽셀만 포함 (더 보수적)\n",
    "            out_image, out_transform = rasterio.mask.mask(\n",
    "                src, \n",
    "                gdf_mask_reprojected.geometry, \n",
    "                crop=True,\n",
    "                all_touched=False,\n",
    "                nodata=np.nan\n",
    "            )\n",
    "            \n",
    "            # 메타데이터 업데이트\n",
    "            out_meta = src.meta.copy()\n",
    "            out_meta.update({\n",
    "                \"driver\": \"GTiff\",\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform,\n",
    "                \"nodata\": np.nan,\n",
    "                \"compress\": \"lzw\"\n",
    "            })\n",
    "        \n",
    "        # 마스킹 통계 계산\n",
    "        total_pixels = out_image.size\n",
    "        valid_pixels = np.sum(~np.isnan(out_image))\n",
    "        masked_pixels = total_pixels - valid_pixels\n",
    "        valid_ratio = (valid_pixels / total_pixels) * 100\n",
    "        \n",
    "        # 결과 저장\n",
    "        output_filename = f\"masked_{filename}\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "            dest.set_band_description(1, 'BAIS2_Forest_Masked')\n",
    "            dest.update_tags(1,\n",
    "                           MASKING='Forest Area Mask Applied',\n",
    "                           MASK_FILE=os.path.basename(mask_path),\n",
    "                           VALID_PIXELS=str(valid_pixels),\n",
    "                           MASKED_PIXELS=str(masked_pixels),\n",
    "                           VALID_RATIO=f'{valid_ratio:.2f}%')\n",
    "        \n",
    "        # 결과 기록\n",
    "        masking_results.append({\n",
    "            'filename': filename,\n",
    "            'total_pixels': total_pixels,\n",
    "            'valid_pixels': valid_pixels,\n",
    "            'masked_pixels': masked_pixels,\n",
    "            'valid_ratio': valid_ratio,\n",
    "            'output_file': output_filename\n",
    "        })\n",
    "        \n",
    "        success_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)[:100]\n",
    "        print(f\"\\n   ✗ [{idx}] {filename}: 오류 - {error_msg}\")\n",
    "        failed_count += 1\n",
    "        failed_files.append((filename, error_msg))\n",
    "\n",
    "print(f\"\\n   ✅ 마스킹 완료: {success_count}개 성공, {failed_count}개 실패\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. 결과 요약 및 저장\n",
    "# ============================================================\n",
    "print(\"[3/3] 결과 요약 및 저장 중...\")\n",
    "\n",
    "# 마스킹 결과 DataFrame\n",
    "df_masking = pd.DataFrame(masking_results)\n",
    "\n",
    "if len(df_masking) > 0:\n",
    "    # 통계 요약\n",
    "    print(f\"\\n   [마스킹 통계]\")\n",
    "    print(f\"   - 평균 유효 픽셀 비율: {df_masking['valid_ratio'].mean():.2f}%\")\n",
    "    print(f\"   - 총 유효 픽셀: {df_masking['valid_pixels'].sum():,}개\")\n",
    "    print(f\"   - 총 마스킹된 픽셀: {df_masking['masked_pixels'].sum():,}개\")\n",
    "    \n",
    "    # CSV 저장\n",
    "    masking_csv = os.path.join(output_dir, \"masking_results.csv\")\n",
    "    df_masking.to_csv(masking_csv, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n   ✅ 마스킹 결과 저장: {masking_csv}\")\n",
    "\n",
    "# 실패 목록 저장\n",
    "if failed_files:\n",
    "    df_failed = pd.DataFrame(failed_files, columns=['filename', 'error'])\n",
    "    failed_csv = os.path.join(output_dir, \"failed_files.csv\")\n",
    "    df_failed.to_csv(failed_csv, index=False, encoding='utf-8-sig')\n",
    "    print(f\"   ✅ 실패 목록 저장: {failed_csv}\")\n",
    "\n",
    "# 최종 요약 리포트\n",
    "report_path = os.path.join(output_dir, \"masking_report.txt\")\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"BAIS2 산지지역 마스킹 리포트\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(f\"작업 일시: {pd.Timestamp.now()}\\n\")\n",
    "    f.write(f\"입력 경로: {input_dir}\\n\")\n",
    "    f.write(f\"출력 경로: {output_dir}\\n\")\n",
    "    f.write(f\"마스크 파일: {mask_path}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"[마스크 정보]\\n\")\n",
    "    f.write(f\"  피처 수: {len(gdf_mask)}개\\n\")\n",
    "    f.write(f\"  CRS: {gdf_mask.crs}\\n\")\n",
    "    f.write(f\"  총 면적: {gdf_mask.geometry.area.sum() / 1e6:.2f} km²\\n\\n\")\n",
    "    \n",
    "    f.write(f\"[처리 결과]\\n\")\n",
    "    f.write(f\"  총 파일 수: {len(all_tif_files)}개\\n\")\n",
    "    f.write(f\"  마스킹 완료: {success_count}개\\n\")\n",
    "    f.write(f\"  실패: {failed_count}개\\n\\n\")\n",
    "    \n",
    "    if len(df_masking) > 0:\n",
    "        f.write(f\"[마스킹 통계]\\n\")\n",
    "        f.write(f\"  평균 유효 픽셀 비율: {df_masking['valid_ratio'].mean():.2f}%\\n\")\n",
    "        f.write(f\"  총 유효 픽셀: {df_masking['valid_pixels'].sum():,}개\\n\")\n",
    "        f.write(f\"  총 마스킹된 픽셀: {df_masking['masked_pixels'].sum():,}개\\n\\n\")\n",
    "    \n",
    "    if failed_files:\n",
    "        f.write(f\"[실패한 파일]\\n\")\n",
    "        for filename, error in failed_files[:20]:\n",
    "            f.write(f\"  - {filename}: {error}\\n\")\n",
    "        if len(failed_files) > 20:\n",
    "            f.write(f\"  ... 외 {len(failed_files)-20}개\\n\")\n",
    "\n",
    "print(f\"   ✅ 리포트 저장: {report_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"=== 마스킹 완료 ===\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n 총 {success_count}개 파일이 마스킹되어 저장되었습니다.\")\n",
    "print(f\" 출력 경로: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bcf95c",
   "metadata": {},
   "outputs": [],
   "source": "# dBAIS2 계산 셀\nimport rasterio\nimport numpy as np\nimport pandas as pd\nimport glob\nimport os\nimport re\nfrom rasterio.warp import reproject, Resampling, calculate_default_transform\nfrom rasterio.merge import merge\nfrom tqdm import tqdm\n\nreference_csv = r\"D:\\Landslide\\data\\raw\\산불발생이력\\s2_matches-15.csv\"\npre_id_column = 'pre_product_id'\npost_id_column = 'post_product_id'\n\npre_masked_BAIS2_dir = r\"D:\\Landslide\\data\\processed\\gyeongnam\\S2_outputs\\pre\\BAIS2_masked\"\npost_masked_BAIS2_dir = r\"D:\\Landslide\\data\\processed\\gyeongnam\\S2_outputs\\post\\BAIS2_masked\"\n\noutput_dir = r\"D:\\Landslide\\data\\processed\\gyeongnam\\S2_outputs\\dBAIS2\"\nunpaired_log = os.path.join(output_dir, \"unpaired.log\")\n\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\nprint(\"=\"*70)\nprint(\"=== dBAIS2 계산 시작 ===\")\nprint(\"=\"*70)\nprint(f\"CSV 파일: {reference_csv}\")\nprint(f\"Pre-BAIS2 경로: {pre_masked_BAIS2_dir}\")\nprint(f\"Post-BAIS2 경로: {post_masked_BAIS2_dir}\")\nprint(f\"출력 경로: {output_dir}\\n\")\n\n# ============================================================\n# 1단계: CSV 파일 로드 및 Pair 리스트 생성\n# ============================================================\nprint(\"[1/4] CSV 파일 로드 및 Pair 리스트 생성 중...\")\n\ndf_ref = pd.read_csv(reference_csv, encoding='utf-8-sig')\nprint(f\"   총 레코드 수: {len(df_ref)}개\")\n\n# 짧은 파일명 추출 함수 (20151028_R103_T52SCD 형식으로 변환)\ndef extract_short_name(product_id):\n    \"\"\"\n    S2A_MSIL2A_20151028T020802_N0500_R103_T52SCD_20231009T132010\n    -> 20151028_R103_T52SCD\n    \"\"\"\n    if pd.isna(product_id) or product_id == '':\n        return None\n\n    match = re.search(r'(\\d{8})T\\d+_N\\d+_(R\\d+)_(T\\w+)_', str(product_id))\n    if match:\n        date = match.group(1)\n        orbit = match.group(2)\n        tile = match.group(3)\n        return f\"{date}_{orbit}_{tile}\"\n    return None\n\n# 파일명 디렉토리 매핑 생성\ndef build_file_mapping(directory):\n    \"\"\"디렉토리 내 파일명 → 전체 경로 매핑\n    \n    다음 패턴들을 모두 지원:\n    1. masked_20151028_R103_T52SCD_BAIS2.tif (masked 버전)\n    2. S2A_MSIL2A_20151028T020802_N0500_R103_T52SCD_20231009T132010_BAIS2.tif (원본 버전)\n    3. 20151028_R103_T52SCD_BAIS2.tif (prefix 없는 버전)\n    \"\"\"\n    file_map = {}\n    if not os.path.exists(directory):\n        print(f\"   경고: 경로가 존재하지 않습니다: {directory}\")\n        return file_map\n\n    for tif_file in glob.glob(os.path.join(directory, \"*_BAIS2.tif\")):\n        basename = os.path.basename(tif_file)\n        \n        # 패턴 1: masked_YYYYMMDD_RXXX_TXXXXX_BAIS2.tif\n        if basename.startswith(\"masked_\"):\n            match = re.search(r'masked_(\\d{8}_R\\d+_T\\w+)_BAIS2\\.tif', basename)\n            if match:\n                short_name = match.group(1)\n                file_map[short_name] = tif_file\n                continue\n        \n        # 패턴 2: S2X_MSIL2A_YYYYMMDDTHHMMSS_NXXXX_RXXX_TXXXXX_YYYYMMDDTHHMMSS_BAIS2.tif\n        match = re.search(r'S2[AB]_MSIL2A_(\\d{8})T\\d+_N\\d+_(R\\d+)_(T\\w+)_\\d+T\\d+_BAIS2\\.tif', basename)\n        if match:\n            date = match.group(1)\n            orbit = match.group(2)\n            tile = match.group(3)\n            short_name = f\"{date}_{orbit}_{tile}\"\n            file_map[short_name] = tif_file\n            continue\n        \n        # 패턴 3: YYYYMMDD_RXXX_TXXXXX_BAIS2.tif (prefix 없음)\n        match = re.search(r'^(\\d{8}_R\\d+_T\\w+)_BAIS2\\.tif$', basename)\n        if match:\n            short_name = match.group(1)\n            file_map[short_name] = tif_file\n\n    return file_map\n\npre_file_map = build_file_mapping(pre_masked_BAIS2_dir)\npost_file_map = build_file_mapping(post_masked_BAIS2_dir)\n\nprint(f\"   Pre-BAIS2 파일: {len(pre_file_map)}개\")\nprint(f\"   Post-BAIS2 파일: {len(post_file_map)}개\")\n\n# Pair 리스트 생성\npair_list = []\nunpaired_cases = []\n\nfor idx, row in df_ref.iterrows():\n    fire_id = row['fire_id']\n    fire_date = row['fire_end_date']\n    pre_product = row.get(pre_id_column)\n    post_product = row.get(post_id_column)\n\n    pre_short = extract_short_name(pre_product)\n    post_short = extract_short_name(post_product)\n\n    # Pair 유효성 체크\n    has_pre = pre_short is not None and pre_short in pre_file_map\n    has_post = post_short is not None and post_short in post_file_map\n\n    if has_pre and has_post:\n        # 유효한 Pair\n        pair_list.append({\n            'fire_id': fire_id,\n            'fire_date': fire_date,\n            'pre_short_name': pre_short,\n            'post_short_name': post_short,\n            'pre_file': pre_file_map[pre_short],\n            'post_file': post_file_map[post_short]\n        })\n    else:\n        # Unpaired 케이스\n        reason = []\n        if pre_short is None:\n            reason.append(\"pre_product_id 없음\")\n        elif pre_short not in pre_file_map:\n            reason.append(f\"pre 파일 없음 ({pre_short})\")\n\n        if post_short is None:\n            reason.append(\"post_product_id 없음\")\n        elif post_short not in post_file_map:\n            reason.append(f\"post 파일 없음 ({post_short})\")\n\n        unpaired_cases.append({\n            'fire_id': fire_id,\n            'fire_date': fire_date,\n            'pre_product_id': pre_product,\n            'post_product_id': post_product,\n            'reason': '; '.join(reason)\n        })\n\nprint(f\"\\n   완료: Pair 리스트 생성\")\nprint(f\"      유효한 Pair: {len(pair_list)}개\")\nprint(f\"      Unpaired: {len(unpaired_cases)}개\\n\")\n\n# Unpaired 케이스 로그 저장\nif unpaired_cases:\n    with open(unpaired_log, 'w', encoding='utf-8') as f:\n        f.write(\"=\"*70 + \"\\n\")\n        f.write(\"Unpaired 산불-영상 케이스 로그\\n\")\n        f.write(\"=\"*70 + \"\\n\\n\")\n        f.write(f\"작성 일시: {pd.Timestamp.now()}\\n\")\n        f.write(f\"총 Unpaired 케이스: {len(unpaired_cases)}개\\n\\n\")\n\n        for case in unpaired_cases:\n            f.write(f\"[Fire ID: {case['fire_id']}]\\n\")\n            f.write(f\"  산불 진화일: {case['fire_date']}\\n\")\n            f.write(f\"  Pre-Product ID: {case['pre_product_id']}\\n\")\n            f.write(f\"  Post-Product ID: {case['post_product_id']}\\n\")\n            f.write(f\"  사유: {case['reason']}\\n\\n\")\n\n    print(f\"   Unpaired 로그 저장: {unpaired_log}\\n\")\n\nif len(pair_list) == 0:\n    print(\"오류: 처리할 유효한 Pair가 없습니다.\")\n    raise SystemExit(\"No valid pairs to process\")\n\n# ============================================================\n# 2단계: dBAIS2 계산 함수 정의\n# ============================================================\nprint(\"[2/4] dBAIS2 계산 함수 정의...\")\n\ndef calculate_dbais2_intersection(pre_file, post_file, fire_id, pre_name, post_name, output_dir):\n    \"\"\"\n    두 BAIS2 영상의 겹치는 영역(intersection)에 대해 dBAIS2 계산\n\n    Parameters:\n        pre_file: Pre-fire BAIS2 파일 경로\n        post_file: Post-fire BAIS2 파일 경로\n        fire_id: 산불 ID\n        pre_name: Pre 짧은 이름\n        post_name: Post 짧은 이름\n        output_dir: 출력 디렉토리\n\n    Returns:\n        success: 성공 여부 (bool)\n        message: 결과 메시지\n    \"\"\"\n    try:\n        # Pre/Post 파일 열기\n        with rasterio.open(pre_file) as pre_src, rasterio.open(post_file) as post_src:\n\n            # 두 영상의 경계(bounds) 가져오기\n            pre_bounds = pre_src.bounds\n            post_bounds = post_src.bounds\n\n            # Intersection (겹치는 영역) 계산\n            inter_left = max(pre_bounds.left, post_bounds.left)\n            inter_bottom = max(pre_bounds.bottom, post_bounds.bottom)\n            inter_right = min(pre_bounds.right, post_bounds.right)\n            inter_top = min(pre_bounds.top, post_bounds.top)\n\n            # 겹치는 영역이 있는지 확인\n            if inter_left >= inter_right or inter_bottom >= inter_top:\n                return False, \"No intersection between pre and post images\"\n\n            inter_bounds = (inter_left, inter_bottom, inter_right, inter_top)\n\n            # CRS가 다른 경우 처리\n            if pre_src.crs != post_src.crs:\n                # Post를 Pre의 CRS로 변환\n                post_crs = pre_src.crs\n            else:\n                post_crs = pre_src.crs\n\n            # Pre 영상: intersection 영역만 읽기 (window 사용)\n            pre_window = pre_src.window(*inter_bounds)\n            pre_data = pre_src.read(1, window=pre_window).astype(np.float32)\n            pre_transform = pre_src.window_transform(pre_window)\n\n            # Post 영상: intersection 영역만 읽기 및 리프로젝션\n            post_window = post_src.window(*inter_bounds)\n            post_data_raw = post_src.read(1, window=post_window).astype(np.float32)\n            post_transform_raw = post_src.window_transform(post_window)\n\n            # Post를 Pre 해상도/그리드로 맞추기 (reproject)\n            post_data = np.empty_like(pre_data)\n            reproject(\n                source=post_data_raw,\n                destination=post_data,\n                src_transform=post_transform_raw,\n                src_crs=post_src.crs,\n                dst_transform=pre_transform,\n                dst_crs=post_crs,\n                resampling=Resampling.bilinear,\n                src_nodata=np.nan,\n                dst_nodata=np.nan\n            )\n\n            # dBAIS2 계산: POST - PRE\n            dbais2 = post_data - pre_data\n\n            # 유효 픽셀 마스크 (Pre와 Post 모두 유효한 픽셀만)\n            valid_mask = ~np.isnan(pre_data) & ~np.isnan(post_data)\n            dbais2[~valid_mask] = np.nan\n\n            # 통계 계산\n            valid_pixels = np.sum(valid_mask)\n            if valid_pixels == 0:\n                return False, \"No valid pixels in intersection\"\n\n            dbais2_min = np.nanmin(dbais2)\n            dbais2_max = np.nanmax(dbais2)\n            dbais2_mean = np.nanmean(dbais2)\n            dbais2_std = np.nanstd(dbais2)\n\n            # 출력 파일명 생성\n            output_filename = f\"dBAIS2_fire{fire_id:04d}_{pre_name}_to_{post_name}.tif\"\n            output_path = os.path.join(output_dir, output_filename)\n\n            # 메타데이터 설정\n            profile = pre_src.profile.copy()\n            profile.update({\n                'driver': 'GTiff',\n                'dtype': rasterio.float32,\n                'count': 1,\n                'width': pre_data.shape[1],\n                'height': pre_data.shape[0],\n                'crs': post_crs,\n                'transform': pre_transform,\n                'compress': 'lzw',\n                'nodata': np.nan\n            })\n\n            # 저장\n            with rasterio.open(output_path, 'w', **profile) as dst:\n                dst.write(dbais2, 1)\n                dst.set_band_description(1, 'dBAIS2 (Post - Pre)')\n                dst.update_tags(1,\n                               FIRE_ID=str(fire_id),\n                               PRE_IMAGE=pre_name,\n                               POST_IMAGE=post_name,\n                               FORMULA='POST_BAIS2 - PRE_BAIS2',\n                               VALID_PIXELS=str(valid_pixels),\n                               DBAIS2_MIN=f'{dbais2_min:.6f}',\n                               DBAIS2_MAX=f'{dbais2_max:.6f}',\n                               DBAIS2_MEAN=f'{dbais2_mean:.6f}',\n                               DBAIS2_STD=f'{dbais2_std:.6f}')\n\n            result_msg = (f\"OK: dBAIS2: [{dbais2_min:.3f}, {dbais2_max:.3f}], \"\n                         f\"Mean: {dbais2_mean:.3f}, Valid: {valid_pixels:,}px\")\n\n            return True, result_msg\n\n    except Exception as e:\n        error_msg = f\"Error: {str(e)[:100]}\"\n        return False, error_msg\n\nprint(\"   완료: 함수 정의\\n\")\n\n# ============================================================\n# 3단계: dBAIS2 계산 수행\n# ============================================================\nprint(f\"[3/4] dBAIS2 계산 수행 중 ({len(pair_list)}개 Pair)...\\n\")\n\nresults = []\nsuccess_count = 0\nfail_count = 0\n\nfor pair in tqdm(pair_list, desc=\"   처리 중\"):\n    fire_id = pair['fire_id']\n    pre_file = pair['pre_file']\n    post_file = pair['post_file']\n    pre_name = pair['pre_short_name']\n    post_name = pair['post_short_name']\n\n    success, message = calculate_dbais2_intersection(\n        pre_file, post_file, fire_id, pre_name, post_name, output_dir\n    )\n\n    if success:\n        success_count += 1\n    else:\n        fail_count += 1\n\n    results.append({\n        'fire_id': fire_id,\n        'fire_date': pair['fire_date'],\n        'pre_name': pre_name,\n        'post_name': post_name,\n        'success': success,\n        'message': message\n    })\n\nprint(f\"\\n   완료: 계산 완료 - {success_count}개 성공, {fail_count}개 실패\\n\")\n\n# ============================================================\n# 4단계: 결과 저장\n# ============================================================\nprint(\"[4/4] 결과 저장 중...\")\n\ndf_results = pd.DataFrame(results)\n\n# 결과 CSV 저장\nresults_csv = os.path.join(output_dir, \"dbais2_results.csv\")\ndf_results.to_csv(results_csv, index=False, encoding='utf-8-sig')\nprint(f\"   완료: 결과 CSV 저장 - {results_csv}\")\n\n# 최종 리포트 저장\nreport_path = os.path.join(output_dir, \"dbais2_report.txt\")\nwith open(report_path, 'w', encoding='utf-8') as f:\n    f.write(\"=\"*70 + \"\\n\")\n    f.write(\"dBAIS2 계산 리포트\\n\")\n    f.write(\"=\"*70 + \"\\n\\n\")\n    f.write(f\"작업 일시: {pd.Timestamp.now()}\\n\")\n    f.write(f\"CSV 파일: {reference_csv}\\n\")\n    f.write(f\"출력 경로: {output_dir}\\n\\n\")\n\n    f.write(f\"[처리 결과]\\n\")\n    f.write(f\"  총 레코드 수: {len(df_ref)}개\\n\")\n    f.write(f\"  유효한 Pair: {len(pair_list)}개\\n\")\n    f.write(f\"  Unpaired: {len(unpaired_cases)}개\\n\")\n    f.write(f\"  dBAIS2 계산 성공: {success_count}개\\n\")\n    f.write(f\"  dBAIS2 계산 실패: {fail_count}개\\n\\n\")\n\n    if fail_count > 0:\n        f.write(f\"[실패한 케이스]\\n\")\n        failed = df_results[df_results['success'] == False]\n        for _, row in failed.iterrows():\n            f.write(f\"  Fire ID {row['fire_id']}: {row['message']}\\n\")\n\nprint(f\"   완료: 리포트 저장 - {report_path}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"=== dBAIS2 계산 완료 ===\")\nprint(\"=\"*70)\nprint(f\"\\n 총 {success_count}개 dBAIS2 파일이 생성되었습니다.\")\nprint(f\" 출력 경로: {output_dir}\")\nprint(f\"\\n 주요 파일:\")\nprint(f\"   - dBAIS2 결과: {results_csv}\")\nprint(f\"   - 처리 리포트: {report_path}\")\nif unpaired_cases:\n    print(f\"   - Unpaired 로그: {unpaired_log}\")\nprint()\n"
  },
  {
   "cell_type": "code",
   "id": "hjlz6kbr1tf",
   "source": "# RdBAIS2 계산 셀\nimport rasterio\nimport numpy as np\nimport pandas as pd\nimport glob\nimport os\nimport re\nfrom rasterio.warp import reproject, Resampling, calculate_default_transform\nfrom rasterio.merge import merge\nfrom tqdm import tqdm\n\nreference_csv = r\"D:\\Landslide\\data\\raw\\산불발생이력\\s2_matches-15.csv\"\npre_id_column = 'pre_product_id'\npost_id_column = 'post_product_id'\n\npre_masked_BAIS2_dir = r\"D:\\Landslide\\data\\processed\\gyeongnam\\S2_outputs\\pre\\BAIS2_masked\"\npost_masked_BAIS2_dir = r\"D:\\Landslide\\data\\processed\\gyeongnam\\S2_outputs\\post\\BAIS2_masked\"\n\noutput_dir = r\"D:\\Landslide\\data\\processed\\gyeongnam\\S2_outputs\\RdBAIS2\"\nunpaired_log = os.path.join(output_dir, \"unpaired.log\")\n\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\nprint(\"=\"*70)\nprint(\"=== RdBAIS2 계산 시작 ===\")\nprint(\"=\"*70)\nprint(f\"CSV 파일: {reference_csv}\")\nprint(f\"Pre-BAIS2 경로: {pre_masked_BAIS2_dir}\")\nprint(f\"Post-BAIS2 경로: {post_masked_BAIS2_dir}\")\nprint(f\"출력 경로: {output_dir}\\n\")\n\n# ============================================================\n# 1단계: CSV 파일 로드 및 Pair 리스트 생성\n# ============================================================\nprint(\"[1/4] CSV 파일 로드 및 Pair 리스트 생성 중...\")\n\ndf_ref = pd.read_csv(reference_csv, encoding='utf-8-sig')\nprint(f\"   총 레코드 수: {len(df_ref)}개\")\n\n# 짧은 파일명 추출 함수 (20151028_R103_T52SCD 형식으로 변환)\ndef extract_short_name(product_id):\n    \"\"\"\n    S2A_MSIL2A_20151028T020802_N0500_R103_T52SCD_20231009T132010\n    -> 20151028_R103_T52SCD\n    \"\"\"\n    if pd.isna(product_id) or product_id == '':\n        return None\n\n    match = re.search(r'(\\d{8})T\\d+_N\\d+_(R\\d+)_(T\\w+)_', str(product_id))\n    if match:\n        date = match.group(1)\n        orbit = match.group(2)\n        tile = match.group(3)\n        return f\"{date}_{orbit}_{tile}\"\n    return None\n\n# 파일명 디렉토리 매핑 생성\ndef build_file_mapping(directory):\n    \"\"\"디렉토리 내 파일명 → 전체 경로 매핑\n    \n    다음 패턴들을 모두 지원:\n    1. masked_20151028_R103_T52SCD_BAIS2.tif (masked 버전)\n    2. S2A_MSIL2A_20151028T020802_N0500_R103_T52SCD_20231009T132010_BAIS2.tif (원본 버전)\n    3. 20151028_R103_T52SCD_BAIS2.tif (prefix 없는 버전)\n    \"\"\"\n    file_map = {}\n    if not os.path.exists(directory):\n        print(f\"   경고: 경로가 존재하지 않습니다: {directory}\")\n        return file_map\n\n    for tif_file in glob.glob(os.path.join(directory, \"*_BAIS2.tif\")):\n        basename = os.path.basename(tif_file)\n        \n        # 패턴 1: masked_YYYYMMDD_RXXX_TXXXXX_BAIS2.tif\n        if basename.startswith(\"masked_\"):\n            match = re.search(r'masked_(\\d{8}_R\\d+_T\\w+)_BAIS2\\.tif', basename)\n            if match:\n                short_name = match.group(1)\n                file_map[short_name] = tif_file\n                continue\n        \n        # 패턴 2: S2X_MSIL2A_YYYYMMDDTHHMMSS_NXXXX_RXXX_TXXXXX_YYYYMMDDTHHMMSS_BAIS2.tif\n        match = re.search(r'S2[AB]_MSIL2A_(\\d{8})T\\d+_N\\d+_(R\\d+)_(T\\w+)_\\d+T\\d+_BAIS2\\.tif', basename)\n        if match:\n            date = match.group(1)\n            orbit = match.group(2)\n            tile = match.group(3)\n            short_name = f\"{date}_{orbit}_{tile}\"\n            file_map[short_name] = tif_file\n            continue\n        \n        # 패턴 3: YYYYMMDD_RXXX_TXXXXX_BAIS2.tif (prefix 없음)\n        match = re.search(r'^(\\d{8}_R\\d+_T\\w+)_BAIS2\\.tif$', basename)\n        if match:\n            short_name = match.group(1)\n            file_map[short_name] = tif_file\n\n    return file_map\n\npre_file_map = build_file_mapping(pre_masked_BAIS2_dir)\npost_file_map = build_file_mapping(post_masked_BAIS2_dir)\n\nprint(f\"   Pre-BAIS2 파일: {len(pre_file_map)}개\")\nprint(f\"   Post-BAIS2 파일: {len(post_file_map)}개\")\n\n# Pair 리스트 생성\npair_list = []\nunpaired_cases = []\n\nfor idx, row in df_ref.iterrows():\n    fire_id = row['fire_id']\n    fire_date = row['fire_end_date']\n    pre_product = row.get(pre_id_column)\n    post_product = row.get(post_id_column)\n\n    pre_short = extract_short_name(pre_product)\n    post_short = extract_short_name(post_product)\n\n    # Pair 유효성 체크\n    has_pre = pre_short is not None and pre_short in pre_file_map\n    has_post = post_short is not None and post_short in post_file_map\n\n    if has_pre and has_post:\n        # 유효한 Pair\n        pair_list.append({\n            'fire_id': fire_id,\n            'fire_date': fire_date,\n            'pre_short_name': pre_short,\n            'post_short_name': post_short,\n            'pre_file': pre_file_map[pre_short],\n            'post_file': post_file_map[post_short]\n        })\n    else:\n        # Unpaired 케이스\n        reason = []\n        if pre_short is None:\n            reason.append(\"pre_product_id 없음\")\n        elif pre_short not in pre_file_map:\n            reason.append(f\"pre 파일 없음 ({pre_short})\")\n\n        if post_short is None:\n            reason.append(\"post_product_id 없음\")\n        elif post_short not in post_file_map:\n            reason.append(f\"post 파일 없음 ({post_short})\")\n\n        unpaired_cases.append({\n            'fire_id': fire_id,\n            'fire_date': fire_date,\n            'pre_product_id': pre_product,\n            'post_product_id': post_product,\n            'reason': '; '.join(reason)\n        })\n\nprint(f\"\\n   완료: Pair 리스트 생성\")\nprint(f\"      유효한 Pair: {len(pair_list)}개\")\nprint(f\"      Unpaired: {len(unpaired_cases)}개\\n\")\n\n# Unpaired 케이스 로그 저장\nif unpaired_cases:\n    with open(unpaired_log, 'w', encoding='utf-8') as f:\n        f.write(\"=\"*70 + \"\\n\")\n        f.write(\"Unpaired 산불-영상 케이스 로그\\n\")\n        f.write(\"=\"*70 + \"\\n\\n\")\n        f.write(f\"작성 일시: {pd.Timestamp.now()}\\n\")\n        f.write(f\"총 Unpaired 케이스: {len(unpaired_cases)}개\\n\\n\")\n\n        for case in unpaired_cases:\n            f.write(f\"[Fire ID: {case['fire_id']}]\\n\")\n            f.write(f\"  산불 진화일: {case['fire_date']}\\n\")\n            f.write(f\"  Pre-Product ID: {case['pre_product_id']}\\n\")\n            f.write(f\"  Post-Product ID: {case['post_product_id']}\\n\")\n            f.write(f\"  사유: {case['reason']}\\n\\n\")\n\n    print(f\"   Unpaired 로그 저장: {unpaired_log}\\n\")\n\nif len(pair_list) == 0:\n    print(\"오류: 처리할 유효한 Pair가 없습니다.\")\n    raise SystemExit(\"No valid pairs to process\")\n\n# ============================================================\n# 2단계: RdBAIS2 계산 함수 정의\n# ============================================================\nprint(\"[2/4] RdBAIS2 계산 함수 정의...\")\n\ndef calculate_rdbais2_intersection(pre_file, post_file, fire_id, pre_name, post_name, output_dir):\n    \"\"\"\n    두 BAIS2 영상의 겹치는 영역(intersection)에 대해 RdBAIS2 계산\n    \n    RdBAIS2 (Relativized dBAIS2) = dBAIS2 / sqrt(|preBAIS2| + 1)\n    - 산불 전 식생 상태를 고려한 상대적 피해도 지표\n    - BAIS2는 음수 값을 가질 수 있으므로 +1을 더하여 항상 양수로 만듦\n    - preBAIS2 값이 낮을수록 더 큰 가중치 적용\n\n    Parameters:\n        pre_file: Pre-fire BAIS2 파일 경로\n        post_file: Post-fire BAIS2 파일 경로\n        fire_id: 산불 ID\n        pre_name: Pre 짧은 이름\n        post_name: Post 짧은 이름\n        output_dir: 출력 디렉토리\n\n    Returns:\n        success: 성공 여부 (bool)\n        message: 결과 메시지\n    \"\"\"\n    try:\n        # Pre/Post 파일 열기\n        with rasterio.open(pre_file) as pre_src, rasterio.open(post_file) as post_src:\n\n            # 두 영상의 경계(bounds) 가져오기\n            pre_bounds = pre_src.bounds\n            post_bounds = post_src.bounds\n\n            # Intersection (겹치는 영역) 계산\n            inter_left = max(pre_bounds.left, post_bounds.left)\n            inter_bottom = max(pre_bounds.bottom, post_bounds.bottom)\n            inter_right = min(pre_bounds.right, post_bounds.right)\n            inter_top = min(pre_bounds.top, post_bounds.top)\n\n            # 겹치는 영역이 있는지 확인\n            if inter_left >= inter_right or inter_bottom >= inter_top:\n                return False, \"No intersection between pre and post images\"\n\n            inter_bounds = (inter_left, inter_bottom, inter_right, inter_top)\n\n            # CRS가 다른 경우 처리\n            if pre_src.crs != post_src.crs:\n                # Post를 Pre의 CRS로 변환\n                post_crs = pre_src.crs\n            else:\n                post_crs = pre_src.crs\n\n            # Pre 영상: intersection 영역만 읽기 (window 사용)\n            pre_window = pre_src.window(*inter_bounds)\n            pre_data = pre_src.read(1, window=pre_window).astype(np.float32)\n            pre_transform = pre_src.window_transform(pre_window)\n\n            # Post 영상: intersection 영역만 읽기 및 리프로젝션\n            post_window = post_src.window(*inter_bounds)\n            post_data_raw = post_src.read(1, window=post_window).astype(np.float32)\n            post_transform_raw = post_src.window_transform(post_window)\n\n            # Post를 Pre 해상도/그리드로 맞추기 (reproject)\n            post_data = np.empty_like(pre_data)\n            reproject(\n                source=post_data_raw,\n                destination=post_data,\n                src_transform=post_transform_raw,\n                src_crs=post_src.crs,\n                dst_transform=pre_transform,\n                dst_crs=post_crs,\n                resampling=Resampling.bilinear,\n                src_nodata=np.nan,\n                dst_nodata=np.nan\n            )\n\n            # dBAIS2 계산: POST - PRE\n            dbais2 = post_data - pre_data\n\n            # RdBAIS2 계산: dBAIS2 / sqrt(|preBAIS2| + 1)\n            # BAIS2는 음수 값을 가질 수 있으므로 절댓값에 1을 더함\n            # epsilon을 사용하여 0으로 나누는 것 방지\n            epsilon = 1e-6\n            pre_bais2_abs_plus_one = np.abs(pre_data) + 1.0\n            \n            # 안전한 분모 계산\n            denominator = np.sqrt(pre_bais2_abs_plus_one)\n            denominator_safe = np.where(denominator < epsilon, epsilon, denominator)\n            \n            # RdBAIS2 계산\n            rdbais2 = dbais2 / denominator_safe\n\n            # 유효 픽셀 마스크 (Pre와 Post 모두 유효한 픽셀만)\n            valid_mask = ~np.isnan(pre_data) & ~np.isnan(post_data) & np.isfinite(rdbais2)\n            rdbais2[~valid_mask] = np.nan\n\n            # 통계 계산\n            valid_pixels = np.sum(valid_mask)\n            if valid_pixels == 0:\n                return False, \"No valid pixels in intersection\"\n\n            rdbais2_min = np.nanmin(rdbais2)\n            rdbais2_max = np.nanmax(rdbais2)\n            rdbais2_mean = np.nanmean(rdbais2)\n            rdbais2_std = np.nanstd(rdbais2)\n\n            # 출력 파일명 생성\n            output_filename = f\"RdBAIS2_fire{fire_id:04d}_{pre_name}_to_{post_name}.tif\"\n            output_path = os.path.join(output_dir, output_filename)\n\n            # 메타데이터 설정\n            profile = pre_src.profile.copy()\n            profile.update({\n                'driver': 'GTiff',\n                'dtype': rasterio.float32,\n                'count': 1,\n                'width': pre_data.shape[1],\n                'height': pre_data.shape[0],\n                'crs': post_crs,\n                'transform': pre_transform,\n                'compress': 'lzw',\n                'nodata': np.nan\n            })\n\n            # 저장\n            with rasterio.open(output_path, 'w', **profile) as dst:\n                dst.write(rdbais2, 1)\n                dst.set_band_description(1, 'RdBAIS2 (Relativized dBAIS2)')\n                dst.update_tags(1,\n                               FIRE_ID=str(fire_id),\n                               PRE_IMAGE=pre_name,\n                               POST_IMAGE=post_name,\n                               FORMULA='dBAIS2 / sqrt(|preBAIS2| + 1)',\n                               VALID_PIXELS=str(valid_pixels),\n                               RDBAIS2_MIN=f'{rdbais2_min:.6f}',\n                               RDBAIS2_MAX=f'{rdbais2_max:.6f}',\n                               RDBAIS2_MEAN=f'{rdbais2_mean:.6f}',\n                               RDBAIS2_STD=f'{rdbais2_std:.6f}')\n\n            result_msg = (f\"OK: RdBAIS2: [{rdbais2_min:.3f}, {rdbais2_max:.3f}], \"\n                         f\"Mean: {rdbais2_mean:.3f}, Valid: {valid_pixels:,}px\")\n\n            return True, result_msg\n\n    except Exception as e:\n        error_msg = f\"Error: {str(e)[:100]}\"\n        return False, error_msg\n\nprint(\"   완료: 함수 정의\\n\")\n\n# ============================================================\n# 3단계: RdBAIS2 계산 수행\n# ============================================================\nprint(f\"[3/4] RdBAIS2 계산 수행 중 ({len(pair_list)}개 Pair)...\\n\")\n\nresults = []\nsuccess_count = 0\nfail_count = 0\n\nfor pair in tqdm(pair_list, desc=\"   처리 중\"):\n    fire_id = pair['fire_id']\n    pre_file = pair['pre_file']\n    post_file = pair['post_file']\n    pre_name = pair['pre_short_name']\n    post_name = pair['post_short_name']\n\n    success, message = calculate_rdbais2_intersection(\n        pre_file, post_file, fire_id, pre_name, post_name, output_dir\n    )\n\n    if success:\n        success_count += 1\n    else:\n        fail_count += 1\n\n    results.append({\n        'fire_id': fire_id,\n        'fire_date': pair['fire_date'],\n        'pre_name': pre_name,\n        'post_name': post_name,\n        'success': success,\n        'message': message\n    })\n\nprint(f\"\\n   완료: 계산 완료 - {success_count}개 성공, {fail_count}개 실패\\n\")\n\n# ============================================================\n# 4단계: 결과 저장\n# ============================================================\nprint(\"[4/4] 결과 저장 중...\")\n\ndf_results = pd.DataFrame(results)\n\n# 결과 CSV 저장\nresults_csv = os.path.join(output_dir, \"rdbais2_results.csv\")\ndf_results.to_csv(results_csv, index=False, encoding='utf-8-sig')\nprint(f\"   완료: 결과 CSV 저장 - {results_csv}\")\n\n# 최종 리포트 저장\nreport_path = os.path.join(output_dir, \"rdbais2_report.txt\")\nwith open(report_path, 'w', encoding='utf-8') as f:\n    f.write(\"=\"*70 + \"\\n\")\n    f.write(\"RdBAIS2 계산 리포트\\n\")\n    f.write(\"=\"*70 + \"\\n\\n\")\n    f.write(f\"작업 일시: {pd.Timestamp.now()}\\n\")\n    f.write(f\"CSV 파일: {reference_csv}\\n\")\n    f.write(f\"출력 경로: {output_dir}\\n\\n\")\n\n    f.write(f\"[처리 결과]\\n\")\n    f.write(f\"  총 레코드 수: {len(df_ref)}개\\n\")\n    f.write(f\"  유효한 Pair: {len(pair_list)}개\\n\")\n    f.write(f\"  Unpaired: {len(unpaired_cases)}개\\n\")\n    f.write(f\"  RdBAIS2 계산 성공: {success_count}개\\n\")\n    f.write(f\"  RdBAIS2 계산 실패: {fail_count}개\\n\\n\")\n\n    if fail_count > 0:\n        f.write(f\"[실패한 케이스]\\n\")\n        failed = df_results[df_results['success'] == False]\n        for _, row in failed.iterrows():\n            f.write(f\"  Fire ID {row['fire_id']}: {row['message']}\\n\")\n\nprint(f\"   완료: 리포트 저장 - {report_path}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"=== RdBAIS2 계산 완료 ===\")\nprint(\"=\"*70)\nprint(f\"\\n 총 {success_count}개 RdBAIS2 파일이 생성되었습니다.\")\nprint(f\" 출력 경로: {output_dir}\")\nprint(f\"\\n 주요 파일:\")\nprint(f\"   - RdBAIS2 결과: {results_csv}\")\nprint(f\"   - 처리 리포트: {report_path}\")\nif unpaired_cases:\n    print(f\"   - Unpaired 로그: {unpaired_log}\")\nprint()\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfa557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgispy_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}